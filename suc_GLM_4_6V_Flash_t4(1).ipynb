{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIqarxnsAQyz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bbAePqrpRttr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==5.0.0rc0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD2EBZAaRtwj",
        "outputId": "9a701c9a-6419-4722-d294-cc63b641bbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==5.0.0rc0\n",
            "  Downloading transformers-5.0.0rc0-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0rc0) (3.20.0)\n",
            "Collecting huggingface-hub<2.0,>=1.0.0 (from transformers==5.0.0rc0)\n",
            "  Downloading huggingface_hub-1.2.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0rc0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0rc0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0rc0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0rc0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0rc0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0rc0) (0.22.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0rc0) (0.20.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0rc0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0rc0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0rc0) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0rc0) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0rc0) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0rc0) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0rc0) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0rc0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0rc0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0rc0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0rc0) (2025.11.12)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers==5.0.0rc0) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0rc0) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0rc0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0rc0) (0.16.0)\n",
            "Downloading transformers-5.0.0rc0-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-1.2.2-py3-none-any.whl (520 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m521.0/521.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.3\n",
            "    Uninstalling transformers-4.57.3:\n",
            "      Successfully uninstalled transformers-4.57.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 5.0.0rc0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-1.2.2 transformers-5.0.0rc0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHmkfLgsR5SD",
        "outputId": "a275d51e-efbb-410f-8492-752bd048acd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sjf8N1XZjYEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xzDyu9o8jYBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig # \u0644\u0627\u062d\u0638 \u0627\u0633\u062a\u062e\u062f\u0627\u0645 AutoModel\n",
        "\n",
        "model_id = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0636\u063a\u0637 (4-\u0628\u062a)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "# \u0627\u0644\u062a\u063a\u064a\u064a\u0631 \u0647\u0646\u0627: \u0627\u0633\u062a\u062e\u062f\u0627\u0645 AutoModel \u0628\u062f\u0644\u0627\u064b \u0645\u0646 AutoModelForCausalLM\n",
        "model = AutoModel.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config, # \u062a\u0645\u0631\u064a\u0631 \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0636\u063a\u0637\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True, # \u0636\u0631\u0648\u0631\u064a \u062c\u062f\u0627\u064b \u0644\u062a\u0639\u0631\u064a\u0641 mrope_section\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "print(\"\u062a\u0645 \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u0628\u0635\u0631\u064a \u0628\u0646\u062c\u0627\u062d!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382,
          "referenced_widgets": [
            "80b4862166624294a0ec03e20014f374",
            "9c4e186dbd5048e69023a92fd7733375",
            "23e4f4eadc1d4d8684654e4af81ec065",
            "4ed6c523bbe24b70bc5bed51d134609c",
            "0aa87b38e9ea4dd8abfaac15818212da",
            "47d083ad291e4744acd73fc2f89041a0",
            "983465a1346a40c0a550cdd81b4a7004",
            "58895beb522b4dddaa11fdd36bff6cd7",
            "ae904f3e09f445f79eb5733f61193fea",
            "f0ee07dfd39143a2a524d6e3a1636181",
            "975ca72788d842d495287533f8ccc784",
            "38905fbff4004fd0b5ebb83a7ba45f96",
            "efd296d94be946199620406d807d3fdf",
            "ddc0880b5e2141ef8d2a85dcc694b0fd",
            "bd75663cb15e4a84b3f082ca50ce7d80",
            "85669eda32f64535b88f894c59edd976",
            "266cd9a82c354fc78c0356b7ea1bd327",
            "aaa2f76f900c4f98b62c3cce942f36d8",
            "d4e8e4cf1131419f993e6e418d3f08e6",
            "a3f9dd4e1b4f4046be1e356b8470e44b",
            "5e07925746a24cc5b395b09df500791d",
            "f461da2b3c334f49bf637a5c3d17c270",
            "04975d57879d43449a1dd1254372bb63",
            "976278dfe497456e8b3503c29d07b168",
            "9d9af11d436e40b0bc7457f4f86af38d",
            "0e1f1fe46fd945d0a85e165b243fe2f6",
            "ee256a64d60546a4ad59fac3e1aa2ed0",
            "ecec08afb6e24c1d9219960a09e38133",
            "d348b3368da3419ab3e4c2b2f844f3cb",
            "29b26645d9a343ba824199d119b70b70",
            "23b6e88777944020a902922007d125c0",
            "cf84b51cf9434f31b828781dff3a56aa",
            "4c9b9216482b406f9fd91f72f66a557b",
            "15185df4517e4caaa5782d6e179b86c3",
            "671bd2d4d8db49939a910492818c6184",
            "2e1546a448984abd9107483a478cfb7c",
            "394c549c7c7747bd8cadbfb2f4a1101f",
            "88581909fbfe4a5bb595110a900bea2b",
            "df7427ede708430b83045b0f0400ce7d",
            "d26caff2e2e243b7861938b18831b8c6",
            "5c5aad0683fd470c8d5730b5beaae850",
            "74640b94e4394a26bd384334bb945ea0",
            "896d85c916d64a629021971725b34ad7",
            "b7b149f425ab484b95cdab13f7996570"
          ]
        },
        "outputId": "a52f8956-00f1-4975-8a97-ff81cb4e6c0f",
        "id": "F4nT_BDPjc-a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'mrope_section', 'partial_rotary_factor'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80b4862166624294a0ec03e20014f374"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38905fbff4004fd0b5ebb83a7ba45f96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04975d57879d43449a1dd1254372bb63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/703 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15185df4517e4caaa5782d6e179b86c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Glm4vModel LOAD REPORT from: zai-org/GLM-4.6V-Flash\n",
            "Key            | Status     |  | \n",
            "---------------+------------+--+-\n",
            "lm_head.weight | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u062a\u0645 \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u0628\u0635\u0631\u064a \u0628\u0646\u062c\u0627\u062d!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C6ZVMtdcjX_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRM7b4tUjX72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig, AutoProcessor, Glm4vForConditionalGeneration\n",
        "from PIL import Image\n",
        "\n",
        "MODEL_PATH = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \u0636\u063a\u0637 4-\u0628\u062a\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "\n",
        "model = Glm4vForConditionalGeneration.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# --- \u0627\u0642\u0631\u0623 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u0646 \u0645\u0644\u0641 \u0645\u062d\u0644\u064a ---\n",
        "image_path = \"/content/Grayscale_8bits_palette_sample_image.png\"   # \u0639\u062f\u0651\u0650\u0644 \u0647\u0630\u0627 \u0625\u0644\u0649 \u0645\u0633\u0627\u0631 \u0627\u0644\u0635\u0648\u0631\u0629 \u0639\u0646\u062f\u0643\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \u0631\u0633\u0627\u0644\u0629: \u0635\u0648\u0631\u0629 + \u0646\u0635\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            # \u0644\u0646 \u062a\u062d\u062a\u0627\u062c url \u0644\u0623\u0646 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u062d\u0644\u064a\u0651\u0629\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "# \u062a\u062c\u0647\u064a\u0632 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a: \u0627\u0644\u0635\u0648\u0631 + \u0627\u0644\u0646\u0635\n",
        "chat_template = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "inputs = processor(\n",
        "    text=chat_template,\n",
        "    images=[image],\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# \u0646\u0642\u0644 \u0627\u0644\u062a\u064a\u0646\u0633\u0648\u0631\u0627\u062a \u0625\u0644\u0649 \u0646\u0641\u0633 \u062c\u0647\u0627\u0632 \u0627\u0644\u0646\u0645\u0648\u0630\u062c (GPU \u0623\u0648 CPU)\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "inputs.pop(\"token_type_ids\", None)\n",
        "\n",
        "# \u062a\u0648\u0644\u064a\u062f \u0627\u0644\u0646\u0635 (\u0627\u0644\u0648\u0635\u0641)\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=51)\n",
        "\n",
        "output = processor.decode(\n",
        "    generated_ids[0][ inputs[\"input_ids\"].shape[1]: ],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "99d9ca72235847bc9ceb6e459a879dc7",
            "64fa4dd9a818466d8d55fb4a331a6de2",
            "bb436d37d11842388fd21aec0aa7f012",
            "e3025cba5ab04f59b026c01d27812129",
            "b574811b43824e7c9925d80e65baf5e4",
            "08ed536841e04c949e2e2bf0de4ab8cc",
            "f119385f18f24a04a94070d9981ca72b",
            "273d7a6261e3442ea4f7bcbdd7e5aed5",
            "60163e60096c4b8ab26dec239a6fa32e",
            "ed92613d10294b0d865c68e65ae4b650",
            "9e3a623a4c2a4cfaa6ff42637d765344",
            "7ed2e32089d04c0f8e98d3942ffb8e95",
            "b43da50818184c098e739e1a07425a0c",
            "9ff3ec2903154da592e5c8a2a5462961",
            "d569308f2cbc467883b492da8b6392bb",
            "73b6c09b2ec34cf89c6632af47edc9d3",
            "c7d31d8816f6437bba2b35f60482c0a3",
            "278000772da0495faa81b25e48fc8580",
            "c0317147100d40ffb65358f28d5a99fc",
            "dc792e482ae74b7a8e6bf84d4d7d5af8",
            "7e8b56ca8e3b489e80f73b7f540ef5ca",
            "8b5eba58edb3402ca4e28d3406f4893a",
            "6a506dfb7fec4aa0945ef9a311de970e",
            "5d9e455e121a405a830bbaee10e1428c",
            "b23874f35fed4ca7a51a6f58fd526f37",
            "9de1d96496004ad8803b8d991ae80e9f",
            "01b3e036c66f4ac1a40951d812387b59",
            "c7078438933043dd8215dff2272ae88d",
            "8685e41645ac4187a8d457ff20e131f6",
            "ddee837eecdc4f9fb231ae119509d7e2",
            "cb2c3ebf9a3942d1a143b415ab67f11c",
            "9953d1a9a32541e8a704bfa9c41c7869",
            "d75a34cfbea84bc1bf066adf179d8ee9"
          ]
        },
        "outputId": "de359d3e-05a5-4429-bcac-a1152826a391",
        "id": "t2AEWBqyjYt6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'partial_rotary_factor', 'mrope_section'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99d9ca72235847bc9ceb6e459a879dc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ed2e32089d04c0f8e98d3942ffb8e95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/704 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a506dfb7fec4aa0945ef9a311de970e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>Got it, let's describe this black-and-white image of a parrot. First, the main subject is a parrot, likely a macaw or similar species, with a prominent crest on its head. The parrot is perched on a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "219ab2f5-aa41-443a-ff9c-d44b021d2dcb",
        "id": "pYqZypfIjYt_"
      },
      "source": [
        "from IPython.display import Image as IPImage\n",
        "\n",
        "# \u062a\u0623\u0643\u062f \u0623\u0646 \u0645\u0633\u0627\u0631 \u0627\u0644\u0635\u0648\u0631\u0629 \u0635\u062d\u064a\u062d\n",
        "image_path = \"/content/Grayscale_8bits_palette_sample_image.png\"\n",
        "\n",
        "# \u0639\u0631\u0636 \u0627\u0644\u0635\u0648\u0631\u0629\n",
        "IPImage(filename=image_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAADICAAAAAAv7ke5AABPiUlEQVR42k39yfNtW3IehmWz1trNaX/9bV9Tr6tXhWoIFHqABEjbIGmQFinatOQQw1bIIzOskSIcHnvi/8Ce2BNFWEFZ9sCUHESIstgCKKCKBVTVq9e/d/v7606/m9Vkpgf3FaA9Omd0cq+d59vZfPklAgAaAIK9+sQkZgAAwJUmCF4shFIwJQPwi7OqDAVjL6b1Em737MKxXGYDAAMgcyBkk/Ozi7P8yRfb2LT1xIMns5IpdVJ7i3v1ddCS1ftmTuO+G5O4Ow/CzbPdm9+tdh8/OQg4ADA0eGUVEBBBwVdfwQDUyBAJoQCLqSQ2iFEkZ9UKi6t94Kiv7gPAqOIxIw6X/bYe1UwScYzAIJkaB2OazYx9CFSMiNBrUQAVDbNlHQQ4a7b6+GbvnBjYz80gIAQ2tb/4HVMwM4DSsEsdWskeNUIgiHHH0Abpei2AYEAGhtNmtyGQYexn0cxbTr0mQ/LIyMr54N2xIxMUIbKSdmYxG01mzfz49GUuzUTOX3/0b1xtJQKBAgCgUgFEQjQw9qSkYAiAXnA2qaUrQGDs0IoSu2riyhgpjAAGYIYGXDUpAGQHo+Zk5LCkpAzGnDMW9JImFYs6zhE1p9wZKTI0s6aZS3WwNi6+Nusfsv7cmRC/enamAAbErEVNkRE8qlKop/NZa8gsViQLhsm0dYXbiWQFYANEwGBdRkaAkoZBlZ1nNIdFREuOOZwcV2Lq6lpjzAmdqhQwqWd14HG9kqsnv/W31D1gLaKABsxMaOjAAM0AjLAUAyAHGRBQ+n1vIKMgW7YC6BhEhq7AMCQAQCMEnJw0w0CgqiDZzBwqsSEoqJAChOMLR8HXU92tRlPzlIdsbCllcIT99acv3zyvv9UygAEyo5EZGripK4YAwA4NDQAdIRAT5bjbdmkfybohIQefvJdxzHlIrzyRAHh2RF1CMmmnSQEUUxZjx2LMBArN0Zz9tHaM6ZBUQHMUJYc5HvoUOG7W2+sPbf4ZAyB6RgU0QzBqKCsCkGcAUAAiRpMi5tCwDDmlsWTBSbUDhWaKCV0hAwBABCMY9xqYpl+7l6OAqZrC/Mi5AFkADCdz9q0r4K2LYpBiMiIWns1bLMP2EFO/DV9+6ADMExckEDNAGxyLATKafuVpQpCMqumOXO/BDUdgaCPPUikduqqUQPrVgUHcOGMyrB2SAgsqAtJ0Zra6FkMovVSE3hkFZ4ipqCFC0fmDIx6GPg8DxNl59cIBsnMEbAJgwBAVAIAqioqvIALIAEC6WmJg4rJv20R5bILLfXLojH1RQQNkQM0AVrez9fPOnBIqOqC2MtOuE8eIcWoK3oqAKCVhIi02uXdRFbUxjRGxdNPOASAhODB5dcOoYgBEZvgKZ5GBghQAFgdJ0+nr60vL2beuLyBGzqmZ0Vc+D4jUHh+Fyxv1IGy1ikDT5FRNJWMz8ftqpkCqOSYBRSUqCu3pNEOth10mz90fLZ47QCY0oljQAIXAFADAsiEgAICoIwEmN4jgg19vv/XL/9U/v3hj/K+TJjFADhjVENA8GiAguanrx6QIasw0IA2HBlOe13ubNBLXvg2QUp8AxcAoG5q5YEypJKjIyfqmOAAEVDU1QzBQQEADUzV89T6SXCkDgv3a8e0v/rVfoFL+3t+9e7L9pd3144PH9eMDZgBPqGQIBsyz+WHfGruCjiY9HFf7qwluNrWbVo0l7Z6c3Km7zRp8UVQ0Qypdd9oIASUNoF6yIgBX3kBVixgawitYdGCoBQAA3NLEwoP/5d9o3TJ90fLkTki5dhB3u13/+R/8cKRwjWhGjNP65O1vf7N72j787/6JzTbbig/Nry9/8uScVlvi9s5kLGXY8+lyfVNgn8AECIDUXv/OWcybj2+4hUO2FByAJPCmxbHCzy8EA32Fq2iU2vPffONXv4N5/GD/cN4EuZEKGKuTo3G8/62M05f/5PqRHH/3Ir/xmzPXoinT69945+L/9gfLjvG15ZdlV7EBkgqDIG5vGXwjYIheFc0H7b7ocPPy1sSxlnDsEQCoblOnSKr4VYADwFTIZSwI9+fxjf/4d9Hyai3HM565PGpDO980UPYDt/NKDW6fHJ/O0FCTi6V2xQwLbqqyW16u4b/+v8+obIz98cU0bvbXXQbfTHA3GBKa2HSGQ3J+HxuOvtawCMkBgEbMAoaIQPAKrxBNSSuh9pd+i2ffPYsK25fz5XiYKqMabjbTtILGjmYAIlKdnCtBKc4sJkEBkgS0IDrGY/FX/3mW0Q85tQ7GHIeCQFACgYIZAhRtYNwiTpbjMFK1OMnqSAGkAwDQYGqIhgpAAKhE995a/O5r/hg7CLvuvn8yuV9jhrQp1lSr3fGs8b02hBydQGZ1JWoBUg2AFW4nzKpWnk7+08VR8/L/8YMq7G/3TgkMkal8hYqIOdYLuhmqqTPQzH3FjL68Ch+oADGYoZkCeM5s0+++/66ft/NQN7ItrWh1NImmRYpVc97h3COmEjAoqXhzOHRhIuRRkgFn9cxOetFgMkH88f/5+4po07jqLITKlzwmNjVEdcv7/vbKL2wzqq/rqi78ypd87QwQVM3UAIARqul7v3+BlmnnMHe3IzVVBTcdDftefeUzzKuxF0ZXE+ZB1gyGVYVOEop5KDoRIwAX49h1W08P/8bVD7t61toQAQjIUBWJHIKpKteOIYlCM6sZR+eTAYAWEVSwVwiKBtRe3PuVpqiELDe3BMWP6Ex4ElNbdgH22ELs6wk7RQIEW7ALAmCQtCTvgOqUYGQPphCKbA/TaiLYzETIJ42lcOWjOXASSYZ4WHiXxYSCR/Cte4UKIl/Fza/ggUGP/trFImkWylIUmkB9rgBnmDUXn9ZaU06+0qKAVmKZNGQpIhqU0qU5O9ZSMLMjywIpPV3lT//oOI4sWMWMYMWBAiKTBhXQvTSN5cRNkJ7rygnpVznPq+DEAACJ8OheUywnTrc2aRDQQa4X0kd1Xdc4x6lAcJp75hZBzVTIoKTspBsoJUPnnAF0Cq50fVg0/PrfePmTD55csToWUCIAQGSHBUkJxxIdIbpAY1/VLtR50L+wigzQAIzpbLQwFOBoQSKiWsU8dn2dqYtHjL51jmR9KLWX4KAcItWIzAbdxk9ZB/Lo5NBFm0yaqu2aWdsY/+2rP/i/XgmGqOg9ESIRVpwQyRTClPsRFqfdemReNpAUAAEAAUHxVbJYv3cMErUII7JYRQQEm53tBgPGwz5jCKZXt1RxkpKG/X7UPhMhlZErLeysaLxK5AFDTYp1Q+xg+e0HT28VUENbcSnmOSxOJ5I91XcenrQe6gdv32vTxBXrC3zlWAgKQApAiplS8rmQCXkgGkWLad2OvbTVdgjeSi76EmYZQQ2JkbpSV5igmnQdM1PJdRrbRW1GbnpcDNCloPQ/m/wfnlIFoWFDAKPF/Tfwky+Kq8+WVjxmhWpx0vN37Pbn/z8AAwQEQ5Tq7lHElBiGEdVCKjLNl7ZgO17Ops7CUTCQeEDKpaTk2saTurqRWFzsoAzdMGane/A1F6sdOY+ETpDKg+5xX6oJMZYEFJb3v3Y3SLM8qsdeCQ3yYZTM/6eTq43hz50eAYABvbrXpyOlNCgjpLbsoo/rvQUOzelyfserBZQYTVNKpWrbii1m9jxEotUhlJvbQwqVjBi4u8wLT4gUYxEz4F+ufpAZQ0UlWl2F2cwhLS5OgyhU04Alxgjue1+i/SU2GJLnLOTi6gxXCDajPVZrmQZI7gh0fuImBadvzq+ULG/Qhaqtfc2JHWVk6EfUjt3EbXFa7bvSogqhEQIZiDkp5P0/ePlfberaFH1oKt3dOjvm5Swfri9FdQSnRfnuf/nxXxgFgD4QkmYvxfu+rmpJgnEvzRvLO+ft4qzNi6Z16quKKJQ0qULLXFWW2UapPOWSD4LO53E4bLfFqUB9NK+JUY0CDF1USNX33nq8R1LApmnq49fPOTbni/lxky5f7gDH/X7PP35EX/kWABCiFvNaqjCmrpzq80M7kSGX4zeWFU3Pm4iI+9Ece2duDlVdVQBkhthtNDCXYn0/Wlpd365ud9vb9fXVbigCBDkXODx7OUraDvV7Dz7fOSm8OJ3PH753ISs5WjAiXg/n75/l29Wee4/6Ch6YiKCYIQsGb93uF//9t55d1W60nN5+L/DkuC7DBz/+l5fL2mEm8kvP7LTkISvmvrSVZ9V+H4JHrGYTElHW/c2LJ89vdxkcyub5znnNNeJSPlwPHc6XjSdJo3awnFGxcP+Xv3VU9sU5Z6/qNeRZRQ2JUJQs5/Hr/8nXRv5vLoMcDHf+3OIYqirk/+d/cL8UEKiaMrMx7gUQZV+ogiI0HDJSxdsbA4Sa6nYCEgdwpmClXx/A1W5IE1h+a/loTGWVK17dnh414fCUWrP58q5JNZnVjlSRCRDVAEGRghVyMhH3j377Gn/h9g9eBFHark4dGxjPX//f/gJkLyYzViXI2DhiGdS3EylxF6deXFHO5NBPKdSjcqgnU9pddbgqE8JaxAB/9pydlE3xAbuSjib4Ml9EaBfl6ulNXItDAvSuCnGXmIjNFQHU+bL/7t8HcOlX4/9nyHA+dqumrlHDaftwcVWXJPth2pBhAF95UJc4NGM29GRQ8vycGPtSs/PzWFJ0enPbcUNTiCVCO/of/r/GNliHlpgP3dXp3RN5sa9np/nq5e3N5YpdQdRUfB2wgCIzjElU4pb/J2+t6yiL33r+b6oW9eaOz0GhepAOWzoe9nloJIdghOQRzQNjQpcxQBmTzt28pq4zamaTIZUBDi+HSUknzQAyZMLnj4S4IKN6hTSUy5vXjvBQ03x3+XL34hIDE2JRTeCbaYgcJo0nyJj7+//pqXL0ub57e5gkf+cCC3rfgFbtfLgFbV6bAaoKOTYt46ioAFkCJ3ChojGTc4GbWiXeXr1Y6XzmEStvoNCnyC+eBrVIzrEadLthLCRaDU9fbiXvfMMADs0z+abF5Fmx8h5Ryzf/94VFA0p758tP/NfeO3VcVZ7yaNsBG5qfLEmzllE5G+ahR479cIixk8msrV3Jrq6DM9n3X/7o0VqOl95RzmUYuVWoxieTv/0fv/UnsVFPmrPzOGx5mi8/edzN50mnDkwNwtQ7zMmxqKLj0O3KvXqv7COgbPt4fdP64FxA0TYHytXxtDV2kA2KqIOiYGqqsYhOCIo4Z5YBtdvc3lymtp0bhCttcNh537TUnf/jyaJ68P/+ITmmouDqynaBdpd9PQNf22sOwRQhBMh9j6IA5p2fBX07xTpiGMF/9pjHP/8mN9MZ1Sl4mKqRoSuoIMLZHBURyEYNDpECjVmIkNkhl8PlrqumYTKZhxRTVaUcdGwsnB8xyONnkhSRq14KTk2fPRve+MZyXmP+tlMAguFm0uggRh7y0M4ZJv5hlEKiHocdoPYfPjgF011y0kwUkqsBS1HM2RQdUu1NQ2VtZOqgATJXl5iHfVUdYlv7uoKh900D3Nros5svg+h+9YuTKw/CYUpOiTNL+OYvN+zb+n3HYqg2ADOpkMeYY5JkJ3escEArhecQ1X357Fdy7/MxoBVqJxTyKJZjQUIYgUyxnXloJmV/sCmqs4Rpu80FXIsQuMFuP59bmsz6OOR6AvGw7u//H/eH/f5P/7A/UdPOqsWD7ey8aHNx/4FzBoTFVwjGKAlLVEJJ02VBFUIFauYDLM5mu1PspqOvi9ro2tyNyABmCKaAhm3jACsZqOHWRiHdr14OwRuGwC4cNANT2tusRsAmjF23m9/J0/XXt499gx7gcDu7V/mxSxScR4doiFzVTllBRxMPIweGKoLlwECpf3u41dePQKuync3QwLKl7dDUQq9e8A7AGSQKjiTyUQNqsfQ3vQ9DYcrIh11qJj4dwI95ioUYROuWp1fPb/OH/3J/Supuxkno5uHlk+NaIHVsYmZmqioll6xVywqNW/wdVjBAzbr65OQS7PR40hx7UQutRwWUMWMZM4AhqJpz5CoHZYRlEBn22z7DYuYHZe9120+OZhxHrkqu2SYNEdeTRaimx/D+a/FXfv+1izt+D/Mp9lBxsP1LRgMz0JRiSlnF6hYl56H9vdqMUKMe/vAn1cv9+kv5xgRnCTD4ZBiQPet+VEbFLIrknMcS+21qRMvtFdZ13baTlEhSwdlRTUpRa0g+hIVLxeywsaxJ0S3uNSfv/Ma7u8Ps5Hjqq8KHRx85/qq/I6/ieCDUsVBJkDxmtJz++F/op7fRr+4fHqotTKC4CtVcoAMCA1AZwXlNCJL3241v2aEokgtVhSlm02o6qT2nbgip5H1z1EAulb7cvT7HUcZHCtLcmc1vwm7eXHBJ2+65OnnVqRDFV62yhEMCgLiaZ3Eqw9PvjydPhoXEq6tf8EJcFNiyOrNoU5clgznT7LUfqOz3+7qfKLgJc1XVHqftwfsqIECJY6GuRO8bpJa8cb9uJOfPn5zcXxCZ+87dqz/OrsbNcHuYsQGwAxH4qvhQSgI00Pe+NQJKOnz2XG+fJ1+gP32TG2LPTCJSihkhORNDdlogD0PfD7nLgawMQKFpAyOSVfUkBD+uejXCxKfnbNXEk6bhUGz90ac2uQixqvzxyXL3WVccHsZdcAhIKq/qt2AAmg0QYPzQxIzjbkdu9BCr/e5DPVExECBRJ06FkqiCBwGS0SyPJqPgwCTqjVgTkSNyqK7h22fzFhB95Q7jnBFJddil+aMPq+l8s6/OZyT44s0XH2wv633UqXsFPV/lPvaXtdPPb5qEvuwO1+FvHp6t8uWYChaANBLnEVyAkhUMyGQUsgFd37F0UuVDgRBUe8VZK72aFSTfR/ZGWPKQJ28viAl5q33/ZHW8fn2/Pc9yaNvhX7zx6Gcu8K72jK+aPf+D5AcAwTC/9bZC3h/6F+vl6WSysKNvfPco9oPY2LEbx31vpGBSLO77lHvBsWiKFiANxWPJWX0T9lfeMRCXLU2deb56sU2dO5mzWPAiruzro+lNDEu3Hmz2I3j4wb7NMDtjgq8e4FcmvcqCuOkm3zPtd7vL5+E0vthfHeav7T+pT7iHlksuw3oA7CLEJHnMYyJMnUlx6FgiOk3Cs0XIj24qdAa4PlRVYCBXOWncyZl2pa33WRHTke6safctPX95Zz2rygUdvXeXAf4HR4UIdePFAK3s3nijh/XmyUevN1e3Odyvx82/+9Hw4BzNdbtxgMnCDREkJlSgkmW0gCTmXR7qoMrB1+n6cgcMrr66Im5DHzPyMMDxeaMiWOP1vt68uMs9tmW/Ht1Lftfdicuz9uEp48+7568Sfrr3rdN9BDPbT96l2N88287iYViczbqyXz3+yQ/imwvVksG31VBiRhLjIuNhSOx8IDUac+1MqKnTZvdlgoIB12PL7mrtatfvif20yhp80fU+DP1ssCkMk+MuncWjN8phDaNVTACIiD8/M1q80ax2gIZI5+dpv1Vk5vlRutLFtfjy9L//d4fjaS5q4/VtLCKSjZKkQQiF2WlitaAZQgX96vLWBWPQpFVwl2V29+2F0lFb+yzGblPT7T5jca5Iu6xlNrt58O6Tf3Z5uYn8Fw2Cr66hV0iKCpNaJt0o42p52pGsuqa7Hkpp+MN/86FNh6vVYXUQgj6apoRSOJABMhQCAbVQ09BvV6QAzlFlZe7q2fR4nnfIlVc1wcVsedz9SM+5X4/Lpst2Z/Ynj+4sf/rjbr3iVyHEX3qX4mQBfQKgaQv7rcr41rKj/SrL88HAG9L00Q+uA6YUR8aSVFJRzAmQmYGKun47ZvNW4mqV87ogGPqAi213dHpcp/UeG6fskKtG61mvNWgMrj0M+YUufvT8/ddun1rPFRMYICIgIgFU85OmDD2imxzpei1nS3z+/IsvLjepYjDzk8F8/+zaO4iVHRBTJwElC0QjQxsQV6ucVbooYx+fXfbjEI2np81mXM4ZfGBzpiilnma5Xi3rqxzaKUZNTfXIn73gO69/cSCuCAzQwNAQELiaekHoBbk+OTs+XZ4d717uH++1yGTUEo1tLJRX18nJIu592K/DFCWhRmAliZBuo/NOY+IJXL/YdQPPF74+cfVp7agvzkMCgkITV8rNdWqGbZ5I3nX54u0HX968Hsex+sh4gSLOhWACgODamtKBJziqn//m733vtSmDLi8u7mCum7EqGpPXmFHWe3pjFsWHrvcV5dEOHXEcuuhtZ6Gt0aCq4fGWxM2PJ9i0xQtRTtlMDwaETMWk3w7gdlJocT9ctO40/9Hy/e6j+7tbXjSz0/tfe/OilWgA1cylWHg+H8u93//7r5decrLc08nDizYlZQbNMYMC091vpn2pWAZyJFF2nYfVTUdtPcq0so4bD9Yf/OxkUk/ayVxTGkzFtIgoGuNBVeOhVytdDNP3znR3M5ziByfTYXzruXv34nw5DXm7f/InzwBy33gruRydvfsPv+euBoPSjdfPUzMLcQ1YSqWCZGTNvW9AX7qZkEfoi+4PjH0SYqQ64T5RAHDJ5kQnC1fdqfHoKhZx5BiAhyLBkaQGIY+uEtH1x8PqdNjm4+oGFpf33nP/qAosaZNPX4fDFspeZ55kOPq9v3d2JZQ6nBYdNrMjt6uP0sE1wuQYa8dvXOylf3lUjY7GbDimuUnjoiIFvR3qVhUp6YRocea3H70HUcvADpx32q8CpToMEhsrScfoSn01f6N+3k7pfXafz/w33DdzljwKTY/h+Q8EbJC6le2v/C+OutkeJ0Nf3T0O8xgWD23YfXrZ1RM/ISFPxwq02iZVhm3Lypqr2veHfUO9YzNwNfZbT1S3Fs4//uT9AmBFUA1g36tHszFFyUJlu5+wbyeHck/ENXr8/LvpbWdoOUaee7r35gcHAE1gZ3/1P5zLJN3uT9rDVnX+XrfnSVWmdfvYT6mBEurpBCm9MCnOTKkyTj63NW5vD8cyWQ5bAyeHoRb2zFC//tHn92RQQMxAuneeASx6IQXOm71Cg30fcUhzouStWbpVGXOWApVcdwYhAbmv/69/M1Rc9v7CdpSuGpfr6dPVaZ3TzTDH3Dkt47RO47Nnp9J7LhU5Xh9cYx5Y1/miwhn0GiUxsndKlueLp26mxQgQbAQGQDFN6L2zEBI2NV45ZduBNuUutCP/9naQYk3N13/0hxsCpPb1/+x3RnX95va106stlOFlnqS22maelMvOK2jRfl3fyZc/fCYTrWcDtbD56VDV5na7sFOaT3gczFOXyNg5dgB2nSb7wQwUtGdGZDQw9Bp8rq/GZStcDqfTLIe2Wev0xI1Qw5h33bOPfnaDBlrFf+/X8vXzKzh+e/r8kU0r234Ji/EInj+5uPurn6478ZJS/9TpzeN4/QUv5FDnw7M9Hia4e5HObbwJbYMxYOwSkKGVIo54uGJQjapA3qMWAPSEvZ2bPnimMUyqQMu2K+Bw9ewfOZWc1h897ffDAIqI42/9PpcLOwKaXV+VATk8XH1xPJkuLy/HB6fu6tkaUBXXMUcIctjW/RivRFw6tEewT+fTFd/y64QhXnVuqK2oqvOjln3rhijGroYMjMLsHfjdfiL38RYohsUhE7OS5T/8Gv89SOQ///EqlmJIoP4f/0oen/sZ30lPt3HY9Qjd86d8EmK/XolrLSoYQFEQ523MVCbjM1qsovFsWCWa3IjlGru43WQEIhMwTZuVWOy7IWGoHIo5Rz54Q6Yu1Ui91jjm8vhqVKQr98N/w3+HeH6x+yKjGCCA/U//N+PH//3PZjs8v9rHDsfoJF6nUoUG1pcHHbaJ0NQEGraKtvn4eLq9nc1fZqdpN5R+PgxsQ3/Y9wpGYqpSxs1VdkmsIHtGI6Y6MKMloyL7WAftKks7mUxUoZTz1RNn1AZkgkBZCtjFPyz/5efzX/d//ptXXwLILUwXVN087j5Jrx+d3rzYANVOQCOrc0zgc3Y3t2McjEl3lmW8nHZZRyJCz9ZB9EQikM0F886ILRo1zjNIQTU25K3Npumw33bfucBhID998Es/cz+obJOfd8KAfID8nTv/bP21N/rPh+HqKszxWl5bKL/zCYj4u4v6cl/V1kgcMzM6E3Msq8NBDwtkJDAtedWSIiqaI29DyQRISIG44hCA/Si2ZBYlNcYMDkM6sGvXY8wLWDUOqhzeYX70wY9/ehXFDKuK0vxvHmZ//ZvDk/Q67Xb7JKmnev6i0h2nzfXz60MOIZuNo7oQ2MAyNZS1CB3ASHPOBYwRkcgzOelEzJAJfFvVTVs3k4aZFggKpo4AUAF1zJV0m7O7d9sv+onNB7v7A7c1aM7f3jztxYnJt995eFZfJztpei2Pru8vNzsJV6cPu6F/shMDxmo/VAhcB0/wip/pKcYrYctaShEldgCInsiPmQDIIYSqCXVg8pU2kguBM0PUgqQGzGNVT3/SnvZ3l4+PGvVXb8/da9OT47sXt8eX13033v/t944xvfhX1Tuwz752t/3BdHc45qVzNztoiSywsQvcOCBGbYpJMJ92jsGsACFI8QyI5DiPTMREPlTBB4doUADQUkAEAFFhAUjYwuB9tVrkN/Z/jr9U+V2D7h+dnizINuvHH3x64/5Hvznh4YP/4vbb+OancrL4zk/W93vI8dnDqVZHHbddN0MHHIi9qnk1whJJiUrxjOAMwOxVzQRN+uyYPYW2DuwYDVCMkbB4VSjmmEAB1XyV+mF+/XK2lnKN8yfbOrhfYmrYn+T7C9xdfO/Ibz/8L15848HINdUB6LY9lPpnj4OTtEC1LhPU5DkAmhKipIIOGYliwOLYFEFMC3pIIMlVtfehqgMAIKF4FVZkBUM1RNIRvZAVdjCZHyiup9+zbvfEP2r5e7c3u05EXL1ff/dv+v7Lf/r45FfvLDe71kYLVk2cPitDVzY8g1J4NnGBiRFUiWIXjYkZNcuCChMiIxCZkWTJNJ3Om3bSBGYABDQC9KrKDhCRmcetBRXPoFBFaHeHw5358PLT837rDuIOUAd22+Hi9c1++6PN6XvHVblUB/spO8hRJFXDZJpSya2riQBAEQ117DqrGQzUJASse6gBVIHJxIi4aqee3auahpkqiiM1QRIGAmZ2IInASAnNE09+Nj2/2K4kjeB6C0G2oc3XQ/h8u0g7f/6aL7ntn7fRneFh6McRQ1Xjvi9ZzYRQijhwoKUUKM4hArHDEHp0+HO6n5HjUAUgRDBDZBMRIBQjKSUEUwcQpnEHNRuylXioQhBtwuRLsy/dzq/UH6yFgZrn/nzLdx5Oc8Jlm1MGRknjQbw/ahi1lBG0MIMKESKAGklyYIjBh0pTVctXqTAzIpoaA4KpGQMiqjG88itVk8LKTTzE1gdlTNstadZRm4l5/9zdq558dDskmy9Om/Z0+qw5uw87nCHOZbtvVdCpxv6kaVG0iGphAlAhVBEAtFQpomAIbpNqD8aoBoDEoDmpIwMBZBVAVFQwQ3x1gICAVcijtHMaXb8dd0lxLBaYZs79lcmD9c/KRAZHzcUdw+liRmF0aTCH63bOpalx3Mza2WJMSSwXZDUrZCIqxqUoAio5BwkZCPgVXQ6BQbQ4RDADRmDigI40KyGTEQEboMuaVtju8u0OxFdjn8uIh5PXHPjpyXJNExry5OvTp3a8bMw1X8aJJoUbLerrqsDO4WIypCwqiVGLMUiRomgKYKo++NRhBaRKiKpmgp40saKKoUNWD94zFVEEIzJDQxARltKluLsqUKYG3RCiG/zc/aChk9999GSnYNUp5XrqyzY0L29Pxc78y8szT36CptvS+2IkiFZIcoGgWnLJooAFkZhidAFVCYDQUFUBZSSHYsUDqkN2BYlcYTMlUyrMOjANNY0IhQyxuJwkhzxs3B/Nv/294+vv/7efm3397tYWSxYON2V8mfmcuRsnMRy5FGR87lIBwlAUTboyEy05GQMQFGPWnuqaKYEDQQRXEAB0YFKKBoDFT0kcECtSLORBBREihcIOE/gI1MxvS865Hre37u6b334wO5usX1zW35y9sCpozMPnRcX36qckNvAMhgrSMGRDJEYFGTv1qDGV3NTeF83IpYQWK8j6ispuDg1QTcnYsiE5D6bi0ESciQQ0KIbq3Mw1qbSzhIKlqwECbvbi/urRfLMjnHtwrwe7cM803R6VDdSoV9Re7Av0HDISeynAxkySVWVsqtSNFn1b+7H4yu+pqZQDa8pECkCgiMUJIHktTEAoktFpROQUvTMtwFJZi1SB9VgRGgMR5IG86/sb19brFyM1s1QvV0/3V9dv5v0pluO+tMfj3kWtMXpq8gCVOEYCqNohu+5QWKitZdRljami4Amndqs1ZTACfcX5YGMC7xgLWUE1QXGlNEFRC2TJ7VQh0Cyg4TR1/dysUXA3ZTbHzc9+vOqXzxdHjdZPH+0u5fVZOczvd7O2WvFBQ0A0AxECM0LmCekgQ/Qe2wZ6nbW+uAChBpIkiGZIaAjAggCGzA7JxsZJUhvIWsg5KJho2jZ+Ihl9O9FFGA3Vl8wFnUBebT//5Ina4Wdfe4sSUWlaTTvfv3xwFMIUNokUcRCRKqlHAARmGtcCYYZ6VKXe3RUsUxOiMhk7cqCICgCGgAiggqBoBAqmBTWVJqRDYacGup8HDIpcL9ZT1xnlDLmouCqX/skn25mD3Q/uLddVK+2dN/DRGJNLJ+jmJzvDMTQwIFfJMxUBIydNZy3VVs1TWp6RE2rHIqa7wVUqRghCoEoEJsAmZq5gQQTnm0PcE/SH4AO5XMxMvUCYdqWpYxnHALpDlwgni+r0tcmn/+76ZH4d1vvpu2/3TbnqJwBooW2SH2ES6qH4UhGCADBz3SRsHCzDDk78WJEjDuQgUxOyK2IIQCZmQACmJGLGBRmJPWA2NTIF2+ZmiI5aS9ocWWkklYKk8cR92i7vHB0tf/mNH23w7SJwOV7cXZSztPONO8zDWKa9I+5aHx2kukUGNUSsarFAYaLVzB+cBQcYACrvScnYCimgQ9NXw18GiGBa0JlwjSklc6AFruJxiS0osJvKTWxJVMAg33ffd/d/Qe++fnb69tsnZ09seFZfwG6EwZy4AzaA4NFrx85pHFupAaUQmq+iOGq9Hh8f1DMhclBxDUc1M/RGhkwGWgBAiyO0YsZmylg5Dwksjn4srslYIREIakw6GgtaJtfHVf/wbF7G+Ztf1x2sr986S51630jZuP3EuU13B5IOHvtN17TGZGDouE0jO0/VBIy9A3TZJrsRoyAooCv4qp6O9Ape1dAACysQWFIHQdOQhfp7cqAGyNFUDp0CiDAPa/dr2+HuGwtXyvJb9w6l3OQpWSGzo6Pba98sg5Xbxbz068KHdR6LGaIBsvmQwQf0dkBWBqQxVS6J4qt5HPAoRpCRUQUQzADQtBQU1gGdryBDgVC0TSMrK4YFJ3GQBFk/db+847ndptNcvSPXtltPwlCXZr16OIfrw0t+pzp58vnDcruLFhX6vkUVgYKKzMqVihmQIHIcm0INRyeGYMbMURCLKSFpcuRMAVSiVWBCGrUOdWcOtrOKE3uxYq7qEK2o1lu3rCA8/eh4IWMbd+mwe+d0mXB43N/nI6pTN5q7/+hFXDuvBUkO7VxKIRUQBOFXEaBhpX6nk8JsHp2DYoBIbSwYTFEELCN4Rig64MjoKY7MgChxKYcLC2SMkl2tyXGHo5u4Q91IG9bPZ0fl0MvB7i28214eUJWmbky3YbGfjFysUkXIw45hGGtBQhNkYE8E2tBsONQsr7IsCKigiOBA8OfkUQQAwqLOBk9C6CiBE2fFj+OCWcAMXFVF5dh7fs3VjXV85/PPFg+rfY8vq1O3ge3L5VFft3gAAm7ao/Vk2CKZAZR9RgVgLJIt1EiIDtkPbitLJEAyr0aumCICW0IzYFADEECwiAHTmoWUm8iU6lFC3De1CJmSa6eBad/fL6fO53GtHMbbbrGn/f4dDnR1cKfLw64HrcxCHfwJXGwHRkCk1JEPOKrIaMEJACIGSuv9tMoeyQC9JHTJSBWBM5jBK0gtTqyw1bmYFmk4al8qgOTirg4DGDqujk/TWMqkq1y6utySq3m3OTq4PZ3XcS/1urvvDoMcNVoGPwE/LuZrh4iaLbFAJb2ZERZEZgCyenCzRESvBqkUGR2YANcGxRANSOGrXiqxBShahmRoVKcEffHNwYHW4GbHh5W623LqNj/7aeQ7J2E35MGt3jrjoZ81L/ZKlbc2aIlu6hK7e7sC3kA0VcoZSLNjdhUSg3eCrm4Gh4iGYJ6KsTBZQucJzByIKYICkwsAnsXl3GumWlAkFX3kqgB1pRzO/O3h4slZ4z7/0eOCu7NJg6Plw/vHq+oOVZMq+jq7hlNdYUbxcry8FhDDIiXYqC6meso+ICAFtgKVI1NgJCDyMXIeveNMpAiIoGIKhgXAALEIE5ipC1K46kEzcAAAVVhWnx7uDYed+7MvCuLVxj20HYzow3w8ffrRobUsI7YtJ5d6QmF3cvuKFkXIUNSSel+hVYgM6rKvgb4ieLA635PrhwmLelEkM1MwBTOy7DEVdMqoGIgKqSuZKU0cmQo2EBFP5Ak9Q+fN4iHlTg+7wFOyj/+ECdM47DYSHDhqwUymbVAVMFVRKaLgORAgEQGQVpAI2TEjSR6xMmqCiWNTMwNDBEQtKkhDMRBFByM6AJ8jWxFH6muwLMIPl+0bp9HxLAoYWeMTbF7+tGLJ6mfnZRYF1npcc6+zfo8wW4joK2QkBdCqdl8N1ROoo6hMxIRFwaKvu8yEhFgAEYohOssmDoTVPAsTd2NthckOLaQybYlYUaj4N1N3fNfzW9PaS0G4/0uluyzeRwwnh+av7GZuJLntmuqwC7hD5+IGCgoUNSkx4uSkCcY1AiKpg4SOiAgVGDNKLIBITgoggRgYEZAyjsYKplWATTcjcxnXfQNR5uScZGGRarWrHrzm/irb80+/3IB0Xvy733KbooUP7kihuMX6i3g3Ihyth+IWPhKAmBpaMaqdCQEhgDpDVTYDJYdxYMsqUABqlOLIRA0UTQktD7EVDhyacexEwYp3K23kOd8jM0WzSBM9Xhy5O6GiXRcH7aaxPjpDNQPcfvCtK2Jf83DrQqD50WhlfjRUezQshmDmWjAOJOjZzKXam5mC86idIRSBTERkYKgihCAqhEUsOXIVeo27XQ4Glur8cnaun3sHmoIydW5+5tV9fna8tdl81KwRdeuK9uPMd9NuPO4doqaWvZyvijWLJ8YZxUcDgJbVtaLqkNiUCQ0QkQqwY+mxsJovrOpMyalRArE6FfYcQmVUYtpde85FYumLVftP9+F8AoAs64lVC3fREjft8jaDFOIndXy04wfBjct1QwVTFATH7WIF1oSeU0EiRW1qgwpzhWxmpt4AEZRBkKuEA3l2aWxR1QgLmoFJYq/mPVeMqGlMJRfxlA695dtKNhFpxgxweNQGcO7B0IfKVRzmkhZ0MyxxO597XT0Qhk/2Oefogd3ZFmS27ACRFZjy0dLAOmMmZhRyrgiSiXpwbXLazxwDOQEWdKqmikyvqPWaSU1j12sTiuYuinAakXd00bhDvfqzVWPrA31OC7+HZfC83TWTgPV3fuUOn1SbVNnCto0rKlbguCGcVsroWA2U5t7Qig+sRZRCW7Ppq6l68k2oSmdCSzeyDGIgZohcaTREQLEUx35MblZByVldHkcNsN5c7mF49LOn8bB6dkm6PKkiz2pNcftii3cms/NqcBQ3UNpjvyRjswztGZFDc0gmBOXkfMht4La2IqJVw/LVgL8iKWXvxFzFWS2DL1nJsQjnw4gcPFuSIgrcNnXlnBbXR/aHoVx98nT1ZDNfWL+6cW9wNNLtWKQavtjcm0KKC4QwbqZhzE0Ay6E05s83goEBDRyMcHGy93NjzwrskS1HQVBGAQKNIiQJccykWE2ykhUzYzQgZswiDolU/DzkkayAVf52za29iFU1mzXjtvvS3XJlknajjIY4O3ntuucpG8N+fbp6YoFjrKgxnVU9Tj0GMFFoJ2U+aTpPYEBsApALoDGagmhkMRggkAQjiCKimNXIkUPNnos4QFUyCMA2+kN1PiTPgbvJqUvCR8eXa/rzQ+xLtymUsbnztdM7b0LxtTiT62cfPCMfoKSiVGhp7qxmZDKjts6nc25JRw2U2WmRJKaCCqUT7ZWtmMYSE+YDRDG0WCAEiMWKGUMqhxFLcc6NBxfOw05dc0dzvby39FVz+s4Dt11vbzV1YeKiX0wnq6PpyxbGRdOl2x4EJlAUcmK3vM0YDixglZxPpi5WLIreKaigiol5NS4pDAdFdM7MUISTOAEQMS1ODRBBACXuNwlXDyFq58tpfhQm9Gv89P7Rsu2xOlm6uTvZpsOwt9CEfX+kP7NviZtT1zlHUHsyqjJITh5at8eLFZCBurPpdADOpsyoikwlQ2GvuVWR2+wRq+koDErIlA1Q0YEZE5GDpJSH2212w6q2PGRfbuwbD+gX/olfHjkKmLipGjcfxOWNzhoe+uDUniznHuDmpE41i2MKzkCKGIbL9s7TPXHbLY7mMTbjCIoOSSVLATFQjKSpDIyGrrbRlILWEkNANUEmIkYSYdR4GDT3tyfrF1uj/eHtN45On/709XkYq2l1eDHMLt2Lmvno5eHoJA8uzn/34z/9phtDfVmHIn0MJq4y1VLGdm4DLvtMHh8s/EabJEiMjCRZyKUOm8qUoc8o4CpTKuaqKOoqFhXHCIhAoEpWDtskZXy2vtmKC7fNedzgv2xLBdkqn2/3yxduOAhusjV1UhrT8NGXbze3p3O/qrBbGZfigiCgjE1T9xvXJMrVxXSQylwxJkVGEVOT3K3qpogvosCeRkEGT07YeSArzApg6LSUIv1mOyLeCLD5Kvb3y7P3frydU3emWjccd4et++6nl/sNtm1g7cfSt4uEpT9d3vTW7RABqR2IwfIBJtsD14Om6YwP6NSxABR0oEKaFeIOw6jtZIoUMGaoGb0iMxZz+ooZWUytZIy5G4D0sgnErv2sXh5mV587XBCBhaaOsQP3fvvn3Xf8+N335bOe3NA02dtV3U73RWJANfQmZFhi0x7YQjPAvL7pWyBjh6ZkBdCALI+DxDL15hjRzKj2CQzIERdGViBUU0FBKpIADUmR3Unfv/PeDX7ANdbTStE5pJS8szvd6f24/M6bm3/ZpY1TLCifp3OqkzcFBTR+lblwHk2w7qXpDxW9Ev8QlIhoqCXHWGIMgM4DOlMPQChm7tW0JxCoQYwKYyERUxJ1YjgLn/H7r395O04EhgFZlV05xNZdtw9/6eqLd0+r4zvDdX06NItM9jyFRctPo1EZySGaWAQVX4i86z+98PiK3Cus2RtILuNqhSEQWCkTzIhmUZRcqbygmZmjcXDDTfIAlDMgmWlbucUhvvHeuOvcKBBnXStY+9Inz6cnbxxruXvG1eZf1FM30mmdJQ25revNppmREhM7UJndvqiKRuNbvFsTEZmJIAJkk9Tt/Wv3v/bd+/FAgTJSVs6dgmQtfQZUxnQ40OZlh2am0g9GXE3cvdNP66/zT5LXmFQFps0C1y9Wau5Hr7V79/aRt3J6+myR6rKa5FZiKDg9v9rPJ6qFiJVAhAiNwaep86ICVl41dwphhnffn26qKbz3By84+ew52DgQiTifwXuc5dUupc2BMqkzrH3yoeXjB+L5ZlWW4XDYxEOfQpMt7kG2fP+7YSvLOwEtf/rj+d3aoIqAdO6pdTe3YapEBVxWdNeXrFbSzdjebdUQdSxkQGK4d2+/e1G1Z1geTj/bJYg9YB7GtD28PNhhdXWzKfvN/rbsB3YeQBE6aOcQvhue9NTjZDaf1ChpTP6oSV9+EqV3v9r8+fKUWyfRf+OfD6flrO8xUHUyGi7Obm7nk9F0YMhhPAQjEh00ggIYpIwGUIji8Obb9ZdvLip/WH1r+k8/7CdpFUC99XHfmKxGbveNrVd7MkJ1YIyeppP13en+xvJ+oMDUnjfuOt9ezdJlp67i/+jx5zw/mbv904P79DD10232ZvMTS1zZzdpNMcZcFGe7x4SqGrty564DQxszOgcIMb72xt3ZZ6PSVprJw+/Gj/bd/uq6hzL2YmViSq9XVG93o5iv0HQoKN5B+40hrHoxJFeZIpRYVMZnXw4cGv6HfTsLs5P86HJy78UH1YzTELMsT8MgU7rqxTUqMdbz8uw2MJQ8dvmNu0yGKatxwDToa99893jI14flnclZXL/5nccfQh5hdrZ0XNfN+Tnbgwftcr01U2BIManssM53j3V7XU1aIm5IBKzPBPsXt9a2U/dT/00HPIyH+dnR1/+/ftprWfkzb7PdmKrzVV7ptBzcxfBi3fpYZUOH86kkhFc9fO3prXsnYfvjfY9S3X25K5+efPuf95pwvx23a/fdJby2/H5aTmJ3MMScKiMITe2hPt0urukMLA9pM2PlZs4V55jNTSo+3TahnZZtePdYxp9233w6tMzHR9iWPgd8OVDMI3G+2VON5PpexvjOPRkFVcS10FXffLe0t4f9x/7CpX4//YwG/vh2Ppsdt+aa9Pa3qgezvb0DkKuzexdHlaHZYZcUTk+Yt4spk9P+oJLBMkAZD0PKIbivb4cnN6/Pxrasnj++96dP4smF5iZx50pq5rONwuCWYegqzxKG7ADMuCQGSLGVAu/8FV9tNlG2n373ooaL9UnSh//g6RF4121z2O/znOe/8kejr791L9QuHDoEHOt0eZM/e7srF06KUbldVVzhplfNGbGsi/vaFe++PDxYyoef/ezjxcPbh8tAkrsqtpxzOHs5uobTlAWRyQYhUFCNhVSyaF/OX5skePqnl7nb4YPZUI7hn33z9H/8p1RGY5+N+4++tqz4HbpnXbbCVcytm02P8+CrCF90NjQzLPV4PQag8SAIWFEekvshNgqX6ci//NGj7fm/f7iTCiu43gfTsTknccWRtV3EoJLA+YJ1ITIP1jPRcf35v7uZh7vTeqFfTh9qGSq9RnzhQKOo5XB3gWbLgmtzlSvCtWo/XuOsScfzNyebj3ZV7hvbDYWh2RladgSq7o/0+CLg40dw+SyVvjnDqyUlsDxOcOC6WqTgnYxTN4rqkKp0PYIotURAqeP7p4f9G++kb8/rptn9OG5nh8U7V+3dOy+SQ2eqVq3uzIaj9Woj5AIzYgXKgSENZbuoZ+EXprS+7ewRWFkcWFANTQDc7RirYyQb95F8e7h74KZkFusXDeahvdg7DpjNsUnuxG92SM8XzazQ0MHswWuLdor1Yr4jfr6N+/7t0s7+23feupruCD2aTYbnF/vqG/SHtso1FntVu7c65DHM63QdNm52elouNv+2CuprEcQBfUZ3Uk1gNzuZZOw3KQzTve8rk6LQN1XsmmOvYEGzK37c4fT6Mjt8NH3TFfBvHb92jANdzEhfPrYQ++E+fvmQr2O4/H4OSgbo1H/z/Glz2vRXURpxhABGIoNyZZjGKmAcDhyWf+sbP3mKJ9XQjdkyALi//Vr58WOo5xO73MHh9tDB9Rllwdw3/jCMk0kXRDFNunHoYtjsGHn3hb93ujyeB3GT11qLz15sp6FDdbXLw46qH3+xbaqCxiypmSQv/z+39F4J0COAVZpVLNiOEIixshyv5t96L378bJPyy+eGEcw9PDsEiN3E77eprFY/0uNuCpl96peVWZwdDz5LBXi4rel51gA6hObiO3dqsrKc8vD5prvNSxIvmD8+qZ/l5vJ4AVyTgaQ8rK/qOqT1b7jbwz5wQPIsVBk4klllYn3FyaiRZ9X8d8oPnlyvajEAcH9SNE+cQXd53VuiS5xYxOhcjtmZJfJx5ox0bKm7PNQeu/rOr/7WmSFYfU+fXBlJdXw4sgjJ7JPH78U7tHy2XlT7vuShK/tudXTRtk3vzv7kpuUKfVNVvmJXuaYtQyDUg1E2cMvVtvpt/bcv+1wAwIWtVaceuHn4/NNRDG/mcn1UitowBoho7TB6wxCt1vN+P6/e/e4v3rUOTo47+8kNkaEmPBZB5TK/6LWd7x5dfcOuYupsvW0aa4bPjvz37lWHD1+0XDkfwIVp24bJpG08uJmoxEAqu9rph8vfeP1f/DcdGjjXbvpwp2mPTs7/9I93o+9H6ye6LTR2dyinw5J2p0SYA5WH+PE7v/v+yaHn5dFs92QlSBrBNURCBq5QfeQJiPLL5zBIaJKWWSqcdj738id9y5SM+n5zxKdTmiC2s/li4kMVMqckMQ3Bfxz+3l/9z/9VD/zX+3G/80fL+WJ5hFdh6ha+V91jc6iOt9m4ebqbkUqmnqdv/53febsM9emd5vrRy5idg2hV9UrGL3WrR49CdX5RHj1lyTp1cHRq87C/EZ2/c/vRy2fggapahqr1DTq3vt11m9XNtiCwDyyqmg+QttPffG9zzf8BDvu91CcX81LJI7zj5uE6QU9tx7P+YFatP1glHyj6k6//8gO16enCXj6/3WUYVdCRC5y19DdPPvvgk+eumaRH55c8lmkNfVigZ2wqOXnw1rs/+5jIhUq7YQqL1patFNDDarPd7rriAvvakXeJhl157Xdn7vWj0rE+P37jxEYybNd4/MVIMvQy5qAovBg572F6573XmriaHC93zw/D3njwoDVq5bXfH1ar3eFwdXCHJrYPw9Pvp5oycmlnqy08uK4n8u7m0k+UG+pzYGqbnec57TadVtVh3cwWZ7PJJLBmGRDTo/k/cNX51/TJTr6cn7bNco6TjdaznZNDC0MEZA3z+ritHr73sNXe32uHD4a87qgGjK0jLHGzXXWlP8TMHnQ37c/ebT/7foMdMh/fG2/wcrNv7n75f/nyY1+QtAylxhPOJuZm3bab1K4c+s31i9nJyaRuQNDwQLfJYbgTYyn7Jy/O62nbk6f54nmnITV4QEQbm1NY/vr7CzzURzU8u+7NFyqJpQ2o3e7FyhV2rsGBmh7HcSmLv/JxsFEZm4cPPy/19GWfXrpPM4MFkhy9m1RhOwvUDDFP7ixgTBhot72an5wtpy2URAWiM/LTxZWEfDvzbtZtaDm981GWhlF2dWFf5M7bv/huFnw4H24213EYFrVXU89lv15vX/QPloZSXF3avtDL39j/0xs6elqm7B68G8aE7YT45TgGD45ButLUM1f8pK78oasvziqrE7UgebxeH84XzaylHErm3z9GTZ/fTE6WzaSKX566+0v3aMjQsEq2IHb2C79xN1F7pz08ed7FVLBGJAxlf/XRetyu+nAWwRWl5En9Znj2h5/fdU9T4+9+9+3njz7fpwxjNwZP7BzFQ+OPK384bn1VXlwfvd4GCtNJM5lMp37crrcp54qFxH104arm8HG+g6rLuzEtT6x+a+x2tAx5dA/m974xwRGWF6sf3Dayz1xV3DtL3X6zv3owGVm2PUXnU3C6BLV/Jbk/e/DXbsb5O6+tXrzcWQ2oUntQ57V07GcVa5h76LYv8MFpgowTMld0et4/Xz/f3y7vzauKGJ3LX/7gyw6Oztr00z9qH7wxXlSrYRyjwjje+61vNnFcns8e/+iL4rpYe+fBpH/5Yl35w6nf9yn7Rc5BKIkDm7VRSScP7rz5/unwZy8+G9kZGCOAq5kOsa3OvY9HC9Sbx7f3vtmis2riOVh28+X8SK630sXKN+7Dy7vtky/8/oe5fLv/yfa4vV4ex7umh11cTn/9d+ZjobM7t3/+dEXuMDaByXR88emzdxZHt+CKAuXLqcuI7FSmC7VJOGxWL6f3X3arm+0WAEERAbhik8HTMri0mxy0f/zE3z2KlYBzRkQMBu30ePnoars/3Ltwi5svfRnMxg83n+Ufehq53tI57Ce33f2/+w4NuXlNv/go3SIVbGsl2V1uvvwQ3q3jylE0MOuuH0LCUAELLHZnz/Phtl9dqrf541ixI1UjcFTg4HgxEzocbnpe3wztMSGDYyeMWUrtENr37332xfPdrnMLqEn7TYb84jJn9zNYzDf1RX/SVd/56/fGfbhf3z656WReKix1FePmZWcVLnnX7p2TbFjcIda4Ms/+xe0vnOhwgNvjAErz7uC8IxIQaAJbrzRbGA9dz9GKclVPsKAaMQFDL3leOTidLD/cddElWnLKQdGKFl9ent58TZrD0eOLX3+XdzI9pc+fbnQwIPYVjptHL+bzfvFGwzKgtySGADIsuDXy4f6LF2+62XFzgCkohMttaMghOfWMliM0UyJMPY9rm5C4dhl2O6mouMo36WZ/f8mEk7PHCVdOXI37XgOAYUAc97fN1th99/07ZUx37jz78NB1ZhUjGu6ePX98/bANeb4oVIyzgQFaPsxpdqDgqre+XL4LqZLgwIHdimslGAVxgDKamzVm41Z5P7QKkF9U8fZLfvfUE6FvypdX71xM68quX0zmrg7cZ2ACMHCG2UY3XNO7E47Rvec/eNR3XQWBxVFaf/580On26i07uFRRsghgAIU7sbYAYP3G45en52O5Xyl6Xq+aEooDS84RjNHPGgTZbn0cprP+YJt/+yPt+pPzY7biiJvhenf/4njZddtNdGGqY1VHMEbgoIcEqvmNc4lpfn///Q32I6inKtr1y/U2G032j9vFCSSS0RcFNcmVGrnFOs/QPbi+vTi9nRarHVyP9Z6Jaum9hxQtTNigO+ihVCc6JByeGgL5jdZZrSpFh8cvl8ftuFe7die+D/MCZhiqcBIuSx+/NjkqpZzc/+yznHZj5YAI4uVnz2keIqgfv3hn0Ql1yYmaGmoWclQNwBYeZL856tuCE+1ua668t2neeJIht/MGMb/sJOPZ9GCv5vtQV5+dvREc9NvnO9Bxi1cpo5m71zyLPOYEoa0nd06nn4XmjZi1vsAfPS17ZTKrKV+9fLreFgslFw/rz+664gZFNXs1VATB7HQoE5ie+2KTBrS1q24yTkKjDSFJTDybOMXNSgCYkOgr5X+Up3+WvvZa88MfPzPM3ntBx4rOzvuxizHrtCF06t7666+TlOm9zU/XNnZkVc0y3n75pTm/rs4rHTPC83zWYgyvlJuIzIGrEFrzzieoysQxsn8JlYTg6kYFykDTCdNQLpUVwEqBr4TPAfMnez3e/Phz9WS+gZqi8+huPJ+Nsde6Dtrg1dHf+kYa8fT46mcHW42elElWtzqjkR2s6wmXfS7OCxdrwBCJ0LRSnOXIjj1PPVkN2PBq3VATfKjnvfGQpovaCbwcGAyg7LsR6JXcEGu8/Om4/6APyFA5JiOqvHvu36Une3XBV6X19//aW32yxb2PfjyWWktwPqQX17Gavf0kquzoPMx4HaupkVIAM2NH5AJg4Wly5LChygs59qthDlhVbTu7hpzcZGJZzse1AICO0hU0RCYRc1IePS8jmQSuEDXHUc19Ht4oLzoq4jmGb//q2aELp+FnP8mwalxTOd49v6ybfa6OrrJCv560PvTgABDYXo02VZ6RHXsKBorm6pFrSNd17XZV3dSuaEfLiUDR4eHTgcxsSBnBsKqZcsogZWRPCl6ALQ+jjuRuvpjHx5FhYuujX/vtai2LNn32IkaZCs053j7dkWYmncbRJ+maQ7EK4qImDFyAmBz6IP0d34WgauAZavLVZ1cNe3RtqG016OyECoz7y6WhIpq80oJmVwXotmpgCIQVK6rkZADkqt1TVVSE7vzv/nY1lua0/3i75348oga768fX7UQ6MQ7zdN2BFrSktfo2S8PREJF97fhwc+qYkMkpNYoV3pQZGblGG7kd22NfNN12vNevPAoMQSJiXWHUBECELvic1cAUfOPeyBpO0hjK2f/8t1Fj+/bVn+12feYj8Lx79vgKGFu3X10k9NOV8eDRSlUaFyE4ViEHlfd+2ExnEJRHzmG6dZMnL9oapQWr2psDTetocXUwVDOAV+r4hJqNRtdMc0KgClQVSxY1lyvvvvEU6Xyv6Rv/q9+grtyffvrpaojZ+Yp09fj5jlDyLkDuJr20sxErjRoo1Q59YAeGwYJ5X4LjV+JEk5oqh9f9xKN65uAPZVJlTdthkkYANEQwQM8mZiUlNx0yIbDmwQHSODpnzty30mqaL3bv/ye/kSOeTp/+eKSciZj19vmTnfNSvKmvuooKtxKqsO+KIXtjB4gEziiJ895jIEKExYRr7jaT2sDcogn1wSaUeLeeLa/hL3SqyWFhLCU651sVyz0UjLXPVqCpPLvvXalv4q//R7+SqGlOPvsg6S46CvW4frFTBgWRBgHHLqALACU0sRTgAM4VRADyPhVDQ3ZsbgzkK9Fnm+AFARtXT3piwPUWJih/qXv0lVwUWoSGwxjV0FsBnw0AEdjJnUfQv/H338iqy6MPvtzHJNw4PzyXUPdJzTRhRc1+W5ELXmmPDqltPTbeiEGZvUuAGdjQu1IROX/90zwxYmLHy5ArSPE6e07552rQhgTkCrILLIMoqoEPUvrcjYASybs/2MTVa//euxLluPnii1F7ah3i/vL5xUx3qqys0eq63saZpYkDhAzT45qhYkNXIQFzwkrEidRRXNOof7E+qZKRC97N4uCpbDOofrWMCAEb9h6V1RAJUjZBM/Mu9iUb6KjYu391yG//g/c6wLPJJ58dbIDaK/UvbhMIV34sYEZZqDnkwdc1DZBwNmkaxYCELhgYlmiuJAyFxZwjiU/bykIG8g7CVVeaUBAo9AIA6LzVNQIVZYqaPUtJoobZgqQMaAIAB3e1vfcffmODcHz6+LN+0MRBqv4qljLW5FHMKapY8Ce3Wzg6opgVLqyaDnnqk0MnJTB3CpLyxAFbcKJPh7kDCCo1+nDdzZbd8dgs7w94rVXjHSGWUrQUjYoDenslBp88s3+188Ky2975z35p8P3p7MMPch+hZfPbVeMuuauBHSshIBCCn1Xb3WQGoKZx4qMGQiYn6p3H0nAp2rpooXLdc248RjdC5Wazz4//6vDFSX0yvzP76E9uqpAMRcogKqDF0FAI0QBsFLAqmwCCsTv6x78iUS7851/sTIAo2PpqcueWdD83ZFIDMkTEILBUy8BJkp84Q0eEDlXJOx4XPLyar2PS1U0V2MgEgp8M+lu/c3u8rpaT0xntn/vx1hTMUlJDAjBCMCYxgJjYIXPOgIbuf/d7McHx0cefHfLQQAW0X8GZyfRZEytkUvBUAMGZUS1Egf3Y1E0g9J6AwQs4jx1QKpCsNIHSc1sSaRANjXPjNxabMvHo9bB9fFhWfYxFnQ3RAJAFODCpSBYABBCq275XUPd7B5Kjk08ejV3nocZ691kzy6h+nMeaQhCFV1p2VvEw6sSxD5OqcYSBPZN6FedgENYdzHwmlP5qXiEUp2USXEv1+MhFZk3d+pOrhZ/GS6cOAgCaImA9c1JKVkF0iAhazWQEdQxjc/z40XqXCI3L9rNH78TUQAh7VqxaTUBYijkPGRsbkfJSbcbM3nkm9JArZ6re7RLpfuriY2sZS4ZSjomXj8qsSJCDpaub9T7KsfckjG2XBUwBwwxzKQoAJoDOldy20cCVHC4+/TKKMAcP6aOXXorFQ5jezDNyYEAPZAqCgCjCls8St0jEQIxAgdiBKJHmzW48cpunLbmcxZk17MueCPTFEOXlZ/UxjYfAU4tIzTz2CQDQQcqkRQBMEMxebfEgd3APXnyst71r0MH+0y+asD1zNC5bP8xbLKQIEHiXa3OaNDsHHpxns6qgM5DKaeBUCH3DA2N+rJMGDX3OWnM1Dra73Vxty3DYXijnw/QsdEDJLyMmQ0BUMxUxMAQETQBdBnCuvnP5aSqFyTzunl5DxSMK9aGti3pxVRIlMCqJiSibej3tySEQEhILMqMhIGPlHN4e/FXwDpyNJU48hnzb2Lh6uadbneY1qhSoxgCRyDlSA8kAURVJHRGOADaqGYh7TT+5hTUEi834fO0WLW7H4uPNmdtGcBzCCA6xillJxTQD1VLXAsRGRITMQGwK6Bnq58+Oz058QWeE412PkyFPNuvn1xZ7VJ0vIfaHuqBkdCkZoMHYlb0F8D74Vm8igEUAELf91x2kYhjq4dHzMAdk67MPt/crGFIg7zMSshUgMySxdJR16kyICNTA0KF3ZsrkiJO2pxUVYLVYGq6b52w3T9Zl7LwnqNohxuHVvj2MCc3ARpPEmpWknlI3/jzCcD9e1f2gnj1++qdwp9DMV31fJp/k2WaIbZ0rSammUCdVI0heL3zfggmxoLEauOB8BmNX07r+xlFjyqTgzNfgXYaNLuhmrLyfmENIMVYVuShjhAVkiTIAOBRB5dH9pVKg65bbHnzt0xd//NQfuHrf65hkuu1nVRexikWSELqQDYBlJAwnhwrx1do0JCX27hVZHnFsz2tDRBPHNG+9t+g39WQGhH6Q0lcl9sM8VAuImU/vLHH39LKAqzISwnAVxr80K18Vz8Hg6o8e8XAozYUezMtEbt6qN4NgyNml4qFKERkcjYGaEJSE6dVWiGLsAlhBAUiL2otRMWAt08q3et1MS2ibM6jH3birmZJhM8Hpkoflm/dxPaUXUgEQIJYy6F+smHTXAA7BXf7wM3ERdf/Z2wpZPT16Z/GyLz5IrlUNGcXQqBpobr5CAG/ABsCi3NamaolzausCaICsqjVr2Ob5DJq8aHJ16sbLYZtthqQjXZxG16JW9y3dkrqqmBQDA3AmBGauGJUK1//6h1EQOcQn7T0bSk3r8WQ2xtZ8lYJ5lwHUTFLhI0+eijIRkgIzUNNEAHW6nwRVp0JgWHgC6G6acgkttfOBeNbojkLlx8sM7awN+xfboKU9HYu4UFu0qIAWmiQlgSuOXHP7r3/YMSC101pimut4evT5zWvLJ/sTUvY5K2JTBgGwUebovGlxRM6ZeTTDti/73GZpSRHNGLTaugmyuw3xg/XR0elZkG3G4pZ3qu1ws+Mzb6b9FthitCQph2kYDAB4Mi9lXIuTEHz/gz/uSAHC3bNTPKAMOczHLU5sK3VW5lQY65wyAmapk2OCjLEkQwW0TJP99oVghSSOCjgWH4qvrC69146P5giIMEZBKPFm3Y2+DEZc7ztM630vimOqgwEAtPNZEh+zcz4MH3z/AAqo/uyOy0085J4Xus1H88P+zGf2YqWiKmQDM98WRNZMMUcFUzahdnroRxkrFSYjRiQtjcvNHpqxPX7PDfsunM2a9XY/lFLM+xzNA+brYcisCgCagosAVFdIRgugyoZnf3yJwAwMyujKLkqfj5rDTWiHLTSVC60zLOAYwCAEKEaaQQ0N0dijqyeTdnrqnTnNFIgcR2lIwgHd5N7rE6zk0OHyzffvu91myNWshpTFBNJ6wKpCBMQxTjwgezbvAcL/H/lzU7Rz+YkkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J-mufdVSjX3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmo7UwEZjX0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iIoAf6gijXwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade transformers bitsandbytes accelerate\n",
        "# \u0625\u0630\u0627 \u0643\u0646\u062a \u062a\u0633\u062a\u062e\u062f\u0645 Kaggle\u060c \u0642\u062f \u062a\u062d\u062a\u0627\u062c \u0644\u062a\u062d\u062f\u064a\u062b \u0627\u0644\u0645\u0643\u062a\u0628\u0627\u062a \u0644\u0623\u0646 \u0627\u0644\u0646\u0633\u062e \u0627\u0644\u0642\u062f\u064a\u0645\u0629 \u062a\u0633\u0628\u0628 \u0645\u0634\u0627\u0643\u0644"
      ],
      "metadata": {
        "id": "n2T4V_P2Rwe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "# \u0645\u0633\u0627\u0631 \u0627\u0644\u0646\u0645\u0648\u0630\u062c\n",
        "model_id = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0636\u063a\u0637 \u0644\u062a\u0642\u0644\u064a\u0644 \u0627\u0644\u062d\u062c\u0645 \u0625\u0644\u0649 4-\u0628\u062a\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16 # \u0627\u0633\u062a\u062e\u062f\u0627\u0645 fp16 \u0644\u0644\u062d\u0633\u0627\u0628\u0627\u062a \u0644\u0632\u064a\u0627\u062f\u0629 \u0627\u0644\u0633\u0631\u0639\u0629\n",
        ")\n",
        "\n",
        "# \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0640 Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "# \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0645\u0639 \u062a\u0648\u0632\u064a\u0639 \u062a\u0644\u0642\u0627\u0626\u064a (\u0645\u0647\u0645 \u0644\u0640 Kaggle) \u0648\u0636\u063a\u0637 (\u0645\u0647\u0645 \u0644\u0640 Colab)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",  # \u0647\u0630\u0627 \u0627\u0644\u0633\u0637\u0631 \u0645\u0647\u0645 \u062c\u062f\u0627\u064b \u0644\u0643\u0627\u062c\u0644 \u0644\u062a\u0648\u0632\u064a\u0639 \u0627\u0644\u062d\u0645\u0644\u060c \u0648\u0644\u0643\u0648\u0644\u0627\u0628 \u0644\u0636\u0628\u0637 \u0627\u0644\u0630\u0627\u0643\u0631\u0629\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True # \u064a\u0645\u0646\u0639 \u0627\u0645\u062a\u0644\u0627\u0621 \u0627\u0644\u0631\u0627\u0645 \u0627\u0644\u0639\u0627\u062f\u064a\u0629 \u0623\u062b\u0646\u0627\u0621 \u0627\u0644\u062a\u062d\u0645\u064a\u0644\n",
        ")\n",
        "\n",
        "print(\"\u062a\u0645 \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0628\u0646\u062c\u0627\u062d!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "SNZCwB5iRtzJ",
        "outputId": "05481308-6fc8-417d-f753-df6057258deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'mrope_section', 'partial_rotary_factor'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized configuration class <class 'transformers.models.glm4v.configuration_glm4v.Glm4vConfig'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of AfmoeConfig, ApertusConfig, ArceeConfig, AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitNetConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, BltConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, CwmConfig, Data2VecTextConfig, DbrxConfig, DeepseekV2Config, DeepseekV3Config, DiffLlamaConfig, DogeConfig, Dots1Config, ElectraConfig, Emu3Config, ErnieConfig, Ernie4_5Config, Ernie4_5_MoeConfig, Exaone4Config, FalconConfig, FalconH1Config, FalconMambaConfig, FlexOlmoConfig, FuyuConfig, GemmaConfig, Gemma2Config, Gemma3Config, Gemma3TextConfig, Gemma3nConfig, Gemma3nTextConfig, GitConfig, GlmConfig, Glm4Config, Glm4MoeConfig, GotOcr2Config, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GptOssConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, GraniteMoeHybridConfig, GraniteMoeSharedConfig, HeliumConfig, HunYuanDenseV1Config, HunYuanMoEV1Config, JambaConfig, JetMoeConfig, Lfm2Config, Lfm2MoeConfig, LlamaConfig, Llama4Config, Llama4TextConfig, LongcatFlashConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegatronBertConfig, MiniMaxConfig, MinistralConfig, Ministral3Config, MistralConfig, MixtralConfig, MllamaConfig, ModernBertDecoderConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NanoChatConfig, NemotronConfig, OlmoConfig, Olmo2Config, Olmo3Config, OlmoeConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, Phi4MultimodalConfig, PhimoeConfig, PLBartConfig, ProphetNetConfig, Qwen2Config, Qwen2MoeConfig, Qwen3Config, Qwen3MoeConfig, Qwen3NextConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, SeedOssConfig, SmolLM3Config, StableLmConfig, Starcoder2Config, TrOCRConfig, VaultGemmaConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, xLSTMConfig, XmodConfig, ZambaConfig, Zamba2Config.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1346103632.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0645\u0639 \u062a\u0648\u0632\u064a\u0639 \u062a\u0644\u0642\u0627\u0626\u064a (\u0645\u0647\u0645 \u0644\u0640 Kaggle) \u0648\u0636\u063a\u0637 (\u0645\u0647\u0645 \u0644\u0640 Colab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnb_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             )\n\u001b[0;32m--> 376\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;34mf\"Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.glm4v.configuration_glm4v.Glm4vConfig'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of AfmoeConfig, ApertusConfig, ArceeConfig, AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitNetConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, BltConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, CwmConfig, Data2VecTextConfig, DbrxConfig, DeepseekV2Config, DeepseekV3Config, DiffLlamaConfig, DogeConfig, Dots1Config, ElectraConfig, Emu3Config, ErnieConfig, Ernie4_5Config, Ernie4_5_MoeConfig, Exaone4Config, FalconConfig, FalconH1Config, FalconMambaConfig, FlexOlmoConfig, FuyuConfig, GemmaConfig, Gemma2Config, Gemma3Config, Gemma3TextConfig, Gemma3nConfig, Gemma3nTextConfig, GitConfig, GlmConfig, Glm4Config, Glm4MoeConfig, GotOcr2Config, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GptOssConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, GraniteMoeHybridConfig, GraniteMoeSharedConfig, HeliumConfig, HunYuanDenseV1Config, HunYuanMoEV1Config, JambaConfig, JetMoeConfig, Lfm2Config, Lfm2MoeConfig, LlamaConfig, Llama4Config, Llama4TextConfig, LongcatFlashConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegatronBertConfig, MiniMaxConfig, MinistralConfig, Ministral3Config, MistralConfig, MixtralConfig, MllamaConfig, ModernBertDecoderConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NanoChatConfig, NemotronConfig, Olm..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, Glm4vForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "MODEL_PATH = \"zai-org/GLM-4.6V-Flash\"\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"url\": \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"describe this image\"\n",
        "            }\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH)\n",
        "model = Glm4vForConditionalGeneration.from_pretrained(\n",
        "    pretrained_model_name_or_path=MODEL_PATH,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "inputs.pop(\"token_type_ids\", None)\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=8192)\n",
        "output_text = processor.decode(generated_ids[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=False)\n",
        "print(output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "xYLFwGKsTN--",
        "outputId": "a1152413-cddc-434c-f69c-03df100c4de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4256502904.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlm4vForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMODEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"zai-org/GLM-4.6V-Flash\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m messages = [\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/processing_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mdynamic_module_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_class_from_dynamic_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve_trust_remote_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractionMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mimage_processing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageProcessingMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mtokenization_python\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcenter_crop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_image_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImagesKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedAudioTokenizerBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodeling_flash_attention_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlazy_import_flash_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mid_tensor_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfQuantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_hf_quantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantizers_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_module_from_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoHfQuantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoQuantizationConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_quantization_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_quantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfQuantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantizers_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_module_from_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantizer_quark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuarkHfQuantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantizer_spqr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpQRHfQuantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantizer_torchao\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchAoHfQuantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquantizer_vptq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVptqHfQuantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_torchao.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torchao_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorchao\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchao\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.14.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchao/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Skipping import of cpp extensions: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m from torchao.quantization import (\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mautoquant\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mquantize_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchao/quantization/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mAffineQuantizedObserverBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 41\u001b[0;31m from .quant_api import (\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mCutlassInt4PackedLayout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mFloat8DynamicActivationFloat8SemiSparseWeightConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\u0634\u063a\u0627\u0644"
      ],
      "metadata": {
        "id": "sKvDw0DLaMkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig # \u0644\u0627\u062d\u0638 \u0627\u0633\u062a\u062e\u062f\u0627\u0645 AutoModel\n",
        "\n",
        "model_id = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0636\u063a\u0637 (4-\u0628\u062a)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "# \u0627\u0644\u062a\u063a\u064a\u064a\u0631 \u0647\u0646\u0627: \u0627\u0633\u062a\u062e\u062f\u0627\u0645 AutoModel \u0628\u062f\u0644\u0627\u064b \u0645\u0646 AutoModelForCausalLM\n",
        "model = AutoModel.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config, # \u062a\u0645\u0631\u064a\u0631 \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0636\u063a\u0637\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True, # \u0636\u0631\u0648\u0631\u064a \u062c\u062f\u0627\u064b \u0644\u062a\u0639\u0631\u064a\u0641 mrope_section\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "print(\"\u062a\u0645 \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u0628\u0635\u0631\u064a \u0628\u0646\u062c\u0627\u062d!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382,
          "referenced_widgets": [
            "80b4862166624294a0ec03e20014f374",
            "9c4e186dbd5048e69023a92fd7733375",
            "23e4f4eadc1d4d8684654e4af81ec065",
            "4ed6c523bbe24b70bc5bed51d134609c",
            "0aa87b38e9ea4dd8abfaac15818212da",
            "47d083ad291e4744acd73fc2f89041a0",
            "983465a1346a40c0a550cdd81b4a7004",
            "58895beb522b4dddaa11fdd36bff6cd7",
            "ae904f3e09f445f79eb5733f61193fea",
            "f0ee07dfd39143a2a524d6e3a1636181",
            "975ca72788d842d495287533f8ccc784",
            "38905fbff4004fd0b5ebb83a7ba45f96",
            "efd296d94be946199620406d807d3fdf",
            "ddc0880b5e2141ef8d2a85dcc694b0fd",
            "bd75663cb15e4a84b3f082ca50ce7d80",
            "85669eda32f64535b88f894c59edd976",
            "266cd9a82c354fc78c0356b7ea1bd327",
            "aaa2f76f900c4f98b62c3cce942f36d8",
            "d4e8e4cf1131419f993e6e418d3f08e6",
            "a3f9dd4e1b4f4046be1e356b8470e44b",
            "5e07925746a24cc5b395b09df500791d",
            "f461da2b3c334f49bf637a5c3d17c270",
            "04975d57879d43449a1dd1254372bb63",
            "976278dfe497456e8b3503c29d07b168",
            "9d9af11d436e40b0bc7457f4f86af38d",
            "0e1f1fe46fd945d0a85e165b243fe2f6",
            "ee256a64d60546a4ad59fac3e1aa2ed0",
            "ecec08afb6e24c1d9219960a09e38133",
            "d348b3368da3419ab3e4c2b2f844f3cb",
            "29b26645d9a343ba824199d119b70b70",
            "23b6e88777944020a902922007d125c0",
            "cf84b51cf9434f31b828781dff3a56aa",
            "4c9b9216482b406f9fd91f72f66a557b",
            "15185df4517e4caaa5782d6e179b86c3",
            "671bd2d4d8db49939a910492818c6184",
            "2e1546a448984abd9107483a478cfb7c",
            "394c549c7c7747bd8cadbfb2f4a1101f",
            "88581909fbfe4a5bb595110a900bea2b",
            "df7427ede708430b83045b0f0400ce7d",
            "d26caff2e2e243b7861938b18831b8c6",
            "5c5aad0683fd470c8d5730b5beaae850",
            "74640b94e4394a26bd384334bb945ea0",
            "896d85c916d64a629021971725b34ad7",
            "b7b149f425ab484b95cdab13f7996570"
          ]
        },
        "id": "DJGZp1FpTOWz",
        "outputId": "a52f8956-00f1-4975-8a97-ff81cb4e6c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'mrope_section', 'partial_rotary_factor'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80b4862166624294a0ec03e20014f374"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38905fbff4004fd0b5ebb83a7ba45f96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04975d57879d43449a1dd1254372bb63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/703 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15185df4517e4caaa5782d6e179b86c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Glm4vModel LOAD REPORT from: zai-org/GLM-4.6V-Flash\n",
            "Key            | Status     |  | \n",
            "---------------+------------+--+-\n",
            "lm_head.weight | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u062a\u0645 \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u0628\u0635\u0631\u064a \u0628\u0646\u062c\u0627\u062d!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from transformers import AutoProcessor\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# 1. \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0636\u063a\u0637 (NF4) - \u0627\u0644\u0633\u0631 \u0641\u064a \u062a\u0634\u063a\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0639\u0644\u0649 T4\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model_id = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "print(\"\u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c (\u0642\u062f \u064a\u0633\u062a\u063a\u0631\u0642 \u062f\u0642\u064a\u0642\u062a\u064a\u0646)...\")\n",
        "\n",
        "# 2. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u0635\u062d\u064a\u062d (ForCausalLM) \u0645\u0639 \u0627\u0644\u0636\u063a\u0637\n",
        "# \u0627\u0633\u062a\u062e\u062f\u0627\u0645 trust_remote_code=True \u0636\u0631\u0648\u0631\u064a \u062c\u062f\u0627\u064b \u0647\u0646\u0627\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config, # \u062a\u0641\u0639\u064a\u0644 NF4\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "# 3. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0645\u0639\u0627\u0644\u062c (Processor)\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "print(\"\u062a\u0645 \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0628\u0636\u063a\u0637 NF4 \u0648\u0647\u0648 \u062c\u0627\u0647\u0632 \u0644\u0644\u062a\u062d\u062f\u062b!\")\n",
        "\n",
        "# ==========================================\n",
        "# \u062a\u062c\u0631\u0628\u0629 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u0622\u0646\n",
        "# ==========================================\n",
        "\n",
        "# \u0635\u0648\u0631\u0629 \u0644\u0644\u062a\u062c\u0631\u0628\u0629\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \u0627\u0644\u0631\u0633\u0627\u0644\u0629\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},\n",
        "            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "# \u062a\u062c\u0647\u064a\u0632 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "\n",
        "# \u0627\u0644\u062a\u0648\u0644\u064a\u062f\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=200)\n",
        "\n",
        "# \u0637\u0628\u0627\u0639\u0629 \u0627\u0644\u0646\u062a\u064a\u062c\u0629\n",
        "generated_text = processor.decode(generated_ids[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "print(\"-\" * 30)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "70QSLm9LXKmZ",
        "outputId": "aea9a665-3bc3-4654-a734-6f41fe09536c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c (\u0642\u062f \u064a\u0633\u062a\u063a\u0631\u0642 \u062f\u0642\u064a\u0642\u062a\u064a\u0646)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'partial_rotary_factor', 'mrope_section'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized configuration class <class 'transformers.models.glm4v.configuration_glm4v.Glm4vConfig'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of AfmoeConfig, ApertusConfig, ArceeConfig, AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitNetConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, BltConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, CwmConfig, Data2VecTextConfig, DbrxConfig, DeepseekV2Config, DeepseekV3Config, DiffLlamaConfig, DogeConfig, Dots1Config, ElectraConfig, Emu3Config, ErnieConfig, Ernie4_5Config, Ernie4_5_MoeConfig, Exaone4Config, FalconConfig, FalconH1Config, FalconMambaConfig, FlexOlmoConfig, FuyuConfig, GemmaConfig, Gemma2Config, Gemma3Config, Gemma3TextConfig, Gemma3nConfig, Gemma3nTextConfig, GitConfig, GlmConfig, Glm4Config, Glm4MoeConfig, GotOcr2Config, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GptOssConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, GraniteMoeHybridConfig, GraniteMoeSharedConfig, HeliumConfig, HunYuanDenseV1Config, HunYuanMoEV1Config, JambaConfig, JetMoeConfig, Lfm2Config, Lfm2MoeConfig, LlamaConfig, Llama4Config, Llama4TextConfig, LongcatFlashConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegatronBertConfig, MiniMaxConfig, MinistralConfig, Ministral3Config, MistralConfig, MixtralConfig, MllamaConfig, ModernBertDecoderConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NanoChatConfig, NemotronConfig, OlmoConfig, Olmo2Config, Olmo3Config, OlmoeConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, Phi4MultimodalConfig, PhimoeConfig, PLBartConfig, ProphetNetConfig, Qwen2Config, Qwen2MoeConfig, Qwen3Config, Qwen3MoeConfig, Qwen3NextConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, SeedOssConfig, SmolLM3Config, StableLmConfig, Starcoder2Config, TrOCRConfig, VaultGemmaConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, xLSTMConfig, XmodConfig, ZambaConfig, Zamba2Config.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-20532925.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# 2. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u0635\u062d\u064a\u062d (ForCausalLM) \u0645\u0639 \u0627\u0644\u0636\u063a\u0637\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# \u0627\u0633\u062a\u062e\u062f\u0627\u0645 trust_remote_code=True \u0636\u0631\u0648\u0631\u064a \u062c\u062f\u0627\u064b \u0647\u0646\u0627\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnb_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# \u062a\u0641\u0639\u064a\u0644 NF4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             )\n\u001b[0;32m--> 376\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;34mf\"Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.glm4v.configuration_glm4v.Glm4vConfig'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of AfmoeConfig, ApertusConfig, ArceeConfig, AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitNetConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, BltConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, CwmConfig, Data2VecTextConfig, DbrxConfig, DeepseekV2Config, DeepseekV3Config, DiffLlamaConfig, DogeConfig, Dots1Config, ElectraConfig, Emu3Config, ErnieConfig, Ernie4_5Config, Ernie4_5_MoeConfig, Exaone4Config, FalconConfig, FalconH1Config, FalconMambaConfig, FlexOlmoConfig, FuyuConfig, GemmaConfig, Gemma2Config, Gemma3Config, Gemma3TextConfig, Gemma3nConfig, Gemma3nTextConfig, GitConfig, GlmConfig, Glm4Config, Glm4MoeConfig, GotOcr2Config, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GptOssConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, GraniteMoeHybridConfig, GraniteMoeSharedConfig, HeliumConfig, HunYuanDenseV1Config, HunYuanMoEV1Config, JambaConfig, JetMoeConfig, Lfm2Config, Lfm2MoeConfig, LlamaConfig, Llama4Config, Llama4TextConfig, LongcatFlashConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegatronBertConfig, MiniMaxConfig, MinistralConfig, Ministral3Config, MistralConfig, MixtralConfig, MllamaConfig, ModernBertDecoderConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NanoChatConfig, NemotronConfig, Olm..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoConfig, BitsAndBytesConfig, AutoProcessor\n",
        "from transformers.dynamic_module_utils import get_class_from_dynamic_module\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model_id = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "print(\"1. \u062c\u0627\u0631\u064a \u0642\u0631\u0627\u0621\u0629 \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0646\u0645\u0648\u0630\u062c...\")\n",
        "# \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0644\u0645\u0639\u0631\u0641\u0629 \u0627\u0633\u0645 \u0627\u0644\u0643\u0644\u0627\u0633 \u0627\u0644\u0635\u062d\u064a\u062d\n",
        "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "# \u0627\u0633\u062a\u062e\u0631\u0627\u062c \u0627\u0633\u0645 \u0627\u0644\u0643\u0644\u0627\u0633 \u0627\u0644\u0645\u0633\u0624\u0648\u0644 \u0639\u0646 \u0627\u0644\u0645\u062d\u0627\u062f\u062b\u0629 \u0645\u0646 \u062f\u0627\u062e\u0644 \u0645\u0644\u0641 \u0627\u0644\u0625\u0639\u062f\u0627\u062f\u0627\u062a\n",
        "# \u0647\u0630\u0627 \u0627\u0644\u0633\u0637\u0631 \u0647\u0648 \u0627\u0644\u062d\u0644 \u0627\u0644\u0633\u062d\u0631\u064a \u0644\u062a\u0641\u0627\u062f\u064a \u062e\u0637\u0623 ValueError\n",
        "class_path = config.auto_map[\"AutoModelForCausalLM\"]\n",
        "print(f\"   \u062a\u0645 \u062a\u062d\u062f\u064a\u062f \u0627\u0644\u0643\u0644\u0627\u0633 \u0627\u0644\u0645\u0637\u0644\u0648\u0628: {class_path}\")\n",
        "\n",
        "# \u062c\u0644\u0628 \u0627\u0644\u0643\u0644\u0627\u0633 \u0628\u0631\u0645\u062c\u064a\u0627\u064b \u0645\u0646 \u0627\u0644\u0645\u0644\u0641\u0627\u062a \u0627\u0644\u0628\u0639\u064a\u062f\u0629\n",
        "ModelClass = get_class_from_dynamic_module(class_path, model_id)\n",
        "\n",
        "print(\"2. \u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0645\u0639 \u0636\u063a\u0637 NF4 (\u0647\u0630\u0647 \u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u0623\u062b\u0642\u0644)...\")\n",
        "# \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0636\u063a\u0637\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0633 \u0627\u0644\u0645\u0633\u062a\u062e\u0631\u062c \u0645\u0628\u0627\u0634\u0631\u0629\n",
        "model = ModelClass.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "print(\"3. \u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0645\u0639\u0627\u0644\u062c (Processor)...\")\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "print(\"\\n\u2705 \u062a\u0645 \u0627\u0644\u062a\u062d\u0645\u064a\u0644 \u0628\u0646\u062c\u0627\u062d! \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u062c\u0627\u0647\u0632 \u0627\u0644\u0622\u0646.\")\n",
        "\n",
        "# ==========================================\n",
        "# \u0627\u062e\u062a\u0628\u0627\u0631 \u0627\u0644\u062a\u0634\u063a\u064a\u0644 \u0627\u0644\u0641\u0648\u0631\u064a\n",
        "# ==========================================\n",
        "\n",
        "# \u062a\u062d\u0645\u064a\u0644 \u0635\u0648\u0631\u0629\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},\n",
        "            {\"type\": \"text\", \"text\": \"Describe this image.\"}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "\n",
        "print(\"4. \u062c\u0627\u0631\u064a \u0627\u0644\u062a\u0648\u0644\u064a\u062f...\")\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=200)\n",
        "\n",
        "result = processor.decode(generated_ids[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "print(\"-\" * 30)\n",
        "print(\"\u0627\u0644\u0631\u062f:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "pArb6myBXKjq",
        "outputId": "ea6a4c36-7fad-4881-e8ff-dfa90b046e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'partial_rotary_factor', 'mrope_section'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. \u062c\u0627\u0631\u064a \u0642\u0631\u0627\u0621\u0629 \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0646\u0645\u0648\u0630\u062c...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Glm4vConfig' object has no attribute 'auto_map'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-995249296.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# \u0627\u0633\u062a\u062e\u0631\u0627\u062c \u0627\u0633\u0645 \u0627\u0644\u0643\u0644\u0627\u0633 \u0627\u0644\u0645\u0633\u0624\u0648\u0644 \u0639\u0646 \u0627\u0644\u0645\u062d\u0627\u062f\u062b\u0629 \u0645\u0646 \u062f\u0627\u062e\u0644 \u0645\u0644\u0641 \u0627\u0644\u0625\u0639\u062f\u0627\u062f\u0627\u062a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# \u0647\u0630\u0627 \u0627\u0644\u0633\u0637\u0631 \u0647\u0648 \u0627\u0644\u062d\u0644 \u0627\u0644\u0633\u062d\u0631\u064a \u0644\u062a\u0641\u0627\u062f\u064a \u062e\u0637\u0623 ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AutoModelForCausalLM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   \u062a\u0645 \u062a\u062d\u062f\u064a\u062f \u0627\u0644\u0643\u0644\u0627\u0633 \u0627\u0644\u0645\u0637\u0644\u0648\u0628: {class_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"attribute_map\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attribute_map\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attribute_map\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     def __init__(\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Glm4vConfig' object has no attribute 'auto_map'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "from transformers import AutoConfig, BitsAndBytesConfig, AutoProcessor\n",
        "from transformers.dynamic_module_utils import get_class_from_dynamic_module\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model_id = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "print(\"1. \u062c\u0627\u0631\u064a \u0627\u0633\u062a\u062e\u0631\u0627\u062c \u0627\u0633\u0645 \u0627\u0644\u0643\u0644\u0627\u0633 \u0627\u0644\u0635\u062d\u064a\u062d \u064a\u062f\u0648\u064a\u0627\u064b...\")\n",
        "# \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0625\u0639\u062f\u0627\u062f\u0627\u062a\n",
        "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "# --- \u0627\u0644\u0625\u0635\u0644\u0627\u062d \u0647\u0646\u0627 ---\n",
        "# \u0628\u062f\u0644\u0627\u064b \u0645\u0646 config.auto_map \u0627\u0644\u062a\u064a \u0633\u0628\u0628\u062a \u0627\u0644\u062e\u0637\u0623\u060c \u0646\u062d\u0648\u0644 \u0627\u0644\u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0644\u0642\u0627\u0645\u0648\u0633 \u062b\u0645 \u0646\u0642\u0631\u0623 \u0645\u0646\u0647\n",
        "# \u0647\u0630\u0627 \u064a\u0636\u0645\u0646 \u0627\u0644\u062d\u0635\u0648\u0644 \u0639\u0644\u0649 \u0627\u0644\u0645\u0633\u0627\u0631 \u062d\u062a\u0649 \u0644\u0648 \u0643\u0627\u0646 \u0627\u0644\u0643\u0627\u0626\u0646 \u064a\u062e\u0641\u064a\u0647\n",
        "config_dict = config.to_dict()\n",
        "class_path = config_dict[\"auto_map\"][\"AutoModelForCausalLM\"]\n",
        "print(f\"   --> \u062a\u0645 \u0627\u0644\u0639\u062b\u0648\u0631 \u0639\u0644\u0649 \u0627\u0644\u0645\u0633\u0627\u0631: {class_path}\")\n",
        "\n",
        "# \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0643\u0644\u0627\u0633 \u0628\u0631\u0645\u062c\u064a\u0627\u064b (Dynamically loading the class)\n",
        "ModelClass = get_class_from_dynamic_module(class_path, model_id)\n",
        "\n",
        "print(\"2. \u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0645\u0639 \u0636\u063a\u0637 NF4 (\u0644\u0644\u062d\u0645\u0627\u064a\u0629 \u0645\u0646 \u0643\u0631\u0627\u0634 \u0627\u0644\u0631\u0627\u0645)...\")\n",
        "# \u0625\u0639\u062f\u0627\u062f\u0627\u062a bitsandbytes \u0644\u062d\u0645\u0627\u064a\u0629 \u0627\u0644\u0630\u0627\u0643\u0631\u0629\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644\u0643\u0644\u0627\u0633 \u0627\u0644\u0645\u0633\u062a\u062e\u0631\u062c\n",
        "model = ModelClass.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "print(\"3. \u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0645\u0639\u0627\u0644\u062c (Processor)...\")\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "print(\"\\n\u2705 \u062a\u0645\u062a \u0627\u0644\u0645\u0647\u0645\u0629! \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u062c\u0627\u0647\u0632 \u062a\u0645\u0627\u0645\u0627\u064b.\")\n",
        "\n",
        "# ==========================================\n",
        "# \u0627\u062e\u062a\u0628\u0627\u0631 \u0627\u0644\u062a\u0634\u063a\u064a\u0644\n",
        "# ==========================================\n",
        "print(\"4. \u062c\u0627\u0631\u064a \u062a\u062c\u0631\u0628\u0629 \u062a\u062d\u0644\u064a\u0644 \u0635\u0648\u0631\u0629...\")\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},\n",
        "            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=200)\n",
        "\n",
        "result = processor.decode(generated_ids[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "print(\"-\" * 30)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "QYssCHTHXKdI",
        "outputId": "6f00267e-e8ea-4ce8-ca9e-9084c3e60994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. \u062c\u0627\u0631\u064a \u0627\u0633\u062a\u062e\u0631\u0627\u062c \u0627\u0633\u0645 \u0627\u0644\u0643\u0644\u0627\u0633 \u0627\u0644\u0635\u062d\u064a\u062d \u064a\u062f\u0648\u064a\u0627\u064b...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'partial_rotary_factor', 'mrope_section'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'auto_map'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2108347330.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# \u0647\u0630\u0627 \u064a\u0636\u0645\u0646 \u0627\u0644\u062d\u0635\u0648\u0644 \u0639\u0644\u0649 \u0627\u0644\u0645\u0633\u0627\u0631 \u062d\u062a\u0649 \u0644\u0648 \u0643\u0627\u0646 \u0627\u0644\u0643\u0627\u0626\u0646 \u064a\u062e\u0641\u064a\u0647\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AutoModelForCausalLM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   --> \u062a\u0645 \u0627\u0644\u0639\u062b\u0648\u0631 \u0639\u0644\u0649 \u0627\u0644\u0645\u0633\u0627\u0631: {class_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'auto_map'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N1dCf4EGYHPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nln814jhYHSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoConfig, BitsAndBytesConfig, AutoProcessor\n",
        "from transformers.dynamic_module_utils import get_class_from_dynamic_module\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model_id = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "print(\"1. \u062c\u0627\u0631\u064a \u0627\u0633\u062a\u062f\u0639\u0627\u0621 \u0643\u0644\u0627\u0633 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0645\u0628\u0627\u0634\u0631\u0629 (\u062a\u062c\u0627\u0648\u0632 \u0627\u0644\u0623\u062e\u0637\u0627\u0621)...\")\n",
        "\n",
        "# --- \u0627\u0644\u062d\u0644 \u0627\u0644\u0633\u062d\u0631\u064a ---\n",
        "# \u0628\u062f\u0644\u0627\u064b \u0645\u0646 \u0627\u0644\u0628\u062d\u062b \u0641\u064a \u0627\u0644\u0625\u0639\u062f\u0627\u062f\u0627\u062a\u060c \u0646\u0637\u0644\u0628 \u0627\u0644\u0645\u0644\u0641 \u0648\u0627\u0644\u0643\u0644\u0627\u0633 \u0628\u0627\u0644\u0627\u0633\u0645 \u0645\u0628\u0627\u0634\u0631\u0629\n",
        "# \u0647\u0630\u0627 \u0627\u0644\u0645\u0633\u0627\u0631 \u0645\u0633\u062a\u0646\u062a\u062c \u0645\u0646 \u0646\u0648\u0639 \u0627\u0644\u0643\u0648\u0646\u0641\u062c \u0627\u0644\u0630\u064a \u0638\u0647\u0631 \u0641\u064a \u0623\u062e\u0637\u0627\u0626\u0643 \u0627\u0644\u0633\u0627\u0628\u0642\u0629\n",
        "try:\n",
        "    ModelClass = get_class_from_dynamic_module(\n",
        "        \"modeling_glm4v.Glm4vForConditionalGeneration\",\n",
        "        model_id\n",
        "    )\n",
        "except OSError:\n",
        "    # \u0645\u062d\u0627\u0648\u0644\u0629 \u0627\u062d\u062a\u064a\u0627\u0637\u064a\u0629 \u0641\u064a \u062d\u0627\u0644 \u0643\u0627\u0646 \u0627\u0633\u0645 \u0627\u0644\u0645\u0644\u0641 \u0645\u062e\u062a\u0644\u0641\u0627\u064b\n",
        "    print(\"   ... \u0645\u062d\u0627\u0648\u0644\u0629 \u0645\u0633\u0627\u0631 \u0628\u062f\u064a\u0644 ...\")\n",
        "    ModelClass = get_class_from_dynamic_module(\n",
        "        \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
        "        model_id\n",
        "    )\n",
        "\n",
        "print(f\"   --> \u062a\u0645 \u062a\u0623\u0643\u064a\u062f \u0627\u0644\u0643\u0644\u0627\u0633: {ModelClass.__name__}\")\n",
        "\n",
        "print(\"2. \u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0645\u0639 \u0636\u063a\u0637 NF4...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# \u0627\u0644\u0622\u0646 \u0646\u062d\u0645\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0628\u0627\u0644\u0643\u0644\u0627\u0633 \u0627\u0644\u0635\u062d\u064a\u062d \u0627\u0644\u0630\u064a \u064a\u0645\u062a\u0644\u0643 (lm_head)\n",
        "model = ModelClass.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "print(\"3. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0645\u0639\u0627\u0644\u062c...\")\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "print(\"\\n\u2705 \u062a\u0645 \u0643\u0633\u0631 \u0627\u0644\u062d\u0644\u0642\u0629 \u0627\u0644\u0645\u0641\u0631\u063a\u0629! \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u062c\u0627\u0647\u0632 \u0644\u0644\u062a\u062d\u062f\u062b.\")\n",
        "\n",
        "# ==========================================\n",
        "# \u0627\u062e\u062a\u0628\u0627\u0631 \u0627\u0644\u062a\u0648\u0644\u064a\u062f (\u0644\u0644\u062a\u0623\u0643\u062f \u0623\u0646 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u064a\u0646\u0637\u0642)\n",
        "# ==========================================\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},\n",
        "            {\"type\": \"text\", \"text\": \"Describe what you see properly.\"}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "\n",
        "print(\"4. \u062c\u0627\u0631\u064a \u0627\u0644\u062a\u0648\u0644\u064a\u062f...\")\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=200)\n",
        "\n",
        "result = processor.decode(generated_ids[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "print(\"-\" * 30)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "oca4g0fNYHVC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "eff2d1ec-1fd4-4f79-8802-4875edc84ec6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. \u062c\u0627\u0631\u064a \u0627\u0633\u062a\u062f\u0639\u0627\u0621 \u0643\u0644\u0627\u0633 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0645\u0628\u0627\u0634\u0631\u0629 (\u062a\u062c\u0627\u0648\u0632 \u0627\u0644\u0623\u062e\u0637\u0627\u0621)...\n",
            "   ... \u0645\u062d\u0627\u0648\u0644\u0629 \u0645\u0633\u0627\u0631 \u0628\u062f\u064a\u0644 ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "zai-org/GLM-4.6V-Flash does not appear to have a file named modeling_chatglm.py. Checkout 'https://huggingface.co/zai-org/GLM-4.6V-Flash/tree/main' for available files.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1056553355.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     ModelClass = get_class_from_dynamic_module(\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;34m\"modeling_glm4v.Glm4vForConditionalGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_class_from_dynamic_module\u001b[0;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;31m# And lastly we get the class inside our newly created module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     final_module = get_cached_module_file(\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_cached_module_file\u001b[0;34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         resolved_module_file = cached_file(\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m         )\n\u001b[0;32m--> 529\u001b[0;31m         raise OSError(\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} does not appear to have {msg}. Checkout 'https://huggingface.co/{path_or_repo_id}/tree/{revision_}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: zai-org/GLM-4.6V-Flash does not appear to have a file named modeling_glm4v.py. Checkout 'https://huggingface.co/zai-org/GLM-4.6V-Flash/tree/main' for available files.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1056553355.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# \u0645\u062d\u0627\u0648\u0644\u0629 \u0627\u062d\u062a\u064a\u0627\u0637\u064a\u0629 \u0641\u064a \u062d\u0627\u0644 \u0643\u0627\u0646 \u0627\u0633\u0645 \u0627\u0644\u0645\u0644\u0641 \u0645\u062e\u062a\u0644\u0641\u0627\u064b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   ... \u0645\u062d\u0627\u0648\u0644\u0629 \u0645\u0633\u0627\u0631 \u0628\u062f\u064a\u0644 ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     ModelClass = get_class_from_dynamic_module(\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;34m\"modeling_chatglm.ChatGLMForConditionalGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmodel_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_class_from_dynamic_module\u001b[0;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;31m# And lastly we get the class inside our newly created module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     final_module = get_cached_module_file(\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mmodule_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".py\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_cached_module_file\u001b[0;34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         resolved_module_file = cached_file(\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmodule_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;34mf\"a file named {missing_entries[0]}\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_entries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mf\"files named {(*missing_entries,)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         )\n\u001b[0;32m--> 529\u001b[0;31m         raise OSError(\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} does not appear to have {msg}. Checkout 'https://huggingface.co/{path_or_repo_id}/tree/{revision_}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;34m\" for available files.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: zai-org/GLM-4.6V-Flash does not appear to have a file named modeling_chatglm.py. Checkout 'https://huggingface.co/zai-org/GLM-4.6V-Flash/tree/main' for available files."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-yLm85rXKZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XXS-tef1XKWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "# 1. \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0627\u0644\u0630\u064a \u062a\u0645 \u062a\u062d\u0645\u064a\u0644\u0647 \u0641\u064a \u0627\u0644\u062e\u0637\u0648\u0629 \u0627\u0644\u0633\u0627\u0628\u0642\u0629\n",
        "# \u0645\u0644\u0627\u062d\u0638\u0629: \u0646\u0633\u062a\u062e\u062f\u0645 \u0627\u0644\u0645\u062a\u063a\u064a\u0631 'model' \u0645\u0646 \u0627\u0644\u062e\u0644\u064a\u0629 \u0627\u0644\u0633\u0627\u0628\u0642\u0629\n",
        "# \u0644\u0627 \u062a\u0642\u0645 \u0628\u0625\u0639\u0627\u062f\u0629 \u062a\u062d\u0645\u064a\u0644\u0647 \u0628\u0640 Glm4vForConditionalGeneration \u0644\u062a\u062c\u0646\u0628 \u0627\u0644\u0643\u0631\u0627\u0634\n",
        "\n",
        "# 2. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0645\u0639\u0627\u0644\u062c (Processor)\n",
        "# \u0647\u0630\u0627 \u0627\u0644\u0645\u0633\u0624\u0648\u0644 \u0639\u0646 \u062a\u062d\u0648\u064a\u0644 \u0627\u0644\u0635\u0648\u0631\u0629 \u0648\u0627\u0644\u0646\u0635 \u0625\u0644\u0649 \u0623\u0631\u0642\u0627\u0645 \u064a\u0641\u0647\u0645\u0647\u0627 \u0627\u0644\u0646\u0645\u0648\u0630\u062c\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    \"zai-org/GLM-4.6V-Flash\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# 3. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u0646 \u0627\u0644\u0631\u0627\u0628\u0637\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
        "\n",
        "# 4. \u062a\u062c\u0647\u064a\u0632 \u0627\u0644\u0631\u0633\u0627\u0644\u0629\n",
        "# \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u064a\u062d\u062a\u0627\u062c \u0643\u0627\u0626\u0646 \u0627\u0644\u0635\u0648\u0631\u0629 (image object) \u0648\u0644\u064a\u0633 \u0627\u0644\u0631\u0627\u0628\u0637\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},\n",
        "            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "# 5. \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a \u0648\u0646\u0642\u0644\u0647\u0627 \u0644\u0644\u0643\u0631\u062a\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "\n",
        "# 6. \u0627\u0644\u062a\u0648\u0644\u064a\u062f (Generation)\n",
        "# \u0646\u0633\u062a\u062e\u062f\u0645 torch.no_grad \u0644\u062a\u0648\u0641\u064a\u0631 \u0627\u0644\u0630\u0627\u0643\u0631\u0629\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=500, do_sample=True, top_k=1)\n",
        "\n",
        "# 7. \u0641\u0643 \u0627\u0644\u062a\u0634\u0641\u064a\u0631 \u0648\u0637\u0628\u0627\u0639\u0629 \u0627\u0644\u0646\u062a\u064a\u062c\u0629\n",
        "# \u0646\u0642\u0648\u0645 \u0628\u0642\u0635 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a \u0644\u0637\u0628\u0627\u0639\u0629 \u0627\u0644\u0631\u062f \u0627\u0644\u062c\u062f\u064a\u062f \u0641\u0642\u0637\n",
        "generated_text = processor.decode(generated_ids[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "XSRX_kKdTU_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import AutoProcessor"
      ],
      "metadata": {
        "id": "RnrZB7AxW_UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u0646 \u0627\u0644\u0631\u0627\u0628\u0637\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
        "\n",
        "# 4. \u062a\u062c\u0647\u064a\u0632 \u0627\u0644\u0631\u0633\u0627\u0644\u0629\n",
        "# \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u064a\u062d\u062a\u0627\u062c \u0643\u0627\u0626\u0646 \u0627\u0644\u0635\u0648\u0631\u0629 (image object) \u0648\u0644\u064a\u0633 \u0627\u0644\u0631\u0627\u0628\u0637\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},\n",
        "            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "# 5. \u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a \u0648\u0646\u0642\u0644\u0647\u0627 \u0644\u0644\u0643\u0631\u062a\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "\n",
        "# 6. \u0627\u0644\u062a\u0648\u0644\u064a\u062f (Generation)\n",
        "# \u0646\u0633\u062a\u062e\u062f\u0645 torch.no_grad \u0644\u062a\u0648\u0641\u064a\u0631 \u0627\u0644\u0630\u0627\u0643\u0631\u0629\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=500, do_sample=True, top_k=1)\n",
        "\n",
        "# 7. \u0641\u0643 \u0627\u0644\u062a\u0634\u0641\u064a\u0631 \u0648\u0637\u0628\u0627\u0639\u0629 \u0627\u0644\u0646\u062a\u064a\u062c\u0629\n",
        "# \u0646\u0642\u0648\u0645 \u0628\u0642\u0635 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a \u0644\u0637\u0628\u0627\u0639\u0629 \u0627\u0644\u0631\u062f \u0627\u0644\u062c\u062f\u064a\u062f \u0641\u0642\u0637\n",
        "generated_text = processor.decode(generated_ids[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "dqWth5LMW5rZ",
        "outputId": "64a411af-da60-4902-f742-32cd662c9b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file <_io.BytesIO object at 0x7f8435b32f20>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2243730852.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u0646 \u0627\u0644\u0631\u0627\u0628\u0637\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 4. \u062a\u062c\u0647\u064a\u0632 \u0627\u0644\u0631\u0633\u0627\u0644\u0629\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3578\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3579\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3580\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7f8435b32f20>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoProcessor, BitsAndBytesConfig\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "model_id = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0636\u063a\u0637 4-\u0628\u062a (\u0636\u0631\u0648\u0631\u064a \u0644\u0640 T4)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "print(\"\u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c (\u0645\u062d\u0627\u0648\u0644\u0629 \u0627\u0644\u062f\u0639\u0645 \u0627\u0644\u0623\u0635\u0644\u064a)...\")\n",
        "\n",
        "try:\n",
        "    # \u0646\u062d\u0627\u0648\u0644 \u0627\u0644\u062a\u062d\u0645\u064a\u0644 \u0628\u062f\u0648\u0646 trust_remote_code \u0644\u0623\u0646 \u0627\u0644\u0645\u0644\u0641\u0627\u062a \u063a\u064a\u0631 \u0645\u0648\u062c\u0648\u062f\u0629\n",
        "    # \u0627\u0644\u0645\u0643\u062a\u0628\u0629 \u0627\u0644\u0645\u062d\u062f\u062b\u0629 \u064a\u062c\u0628 \u0623\u0646 \u062a\u0639\u0631\u0641 Glm4vConfig\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=False, # \u0646\u0644\u063a\u064a \u0647\u0630\u0627 \u0627\u0644\u062e\u064a\u0627\u0631 \u0644\u0623\u0646\u0647 \u0633\u0628\u0628 \u0627\u0644\u0645\u0634\u0643\u0644\u0629\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "except ValueError as e:\n",
        "    print(\"\u0641\u0634\u0644\u062a \u0627\u0644\u0645\u062d\u0627\u0648\u0644\u0629. \u064a\u0628\u062f\u0648 \u0623\u0646 \u062f\u0639\u0645 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0644\u0645 \u064a\u0635\u0644 \u0644\u0644\u0645\u0643\u062a\u0628\u0629 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 \u0628\u0639\u062f.\")\n",
        "    print(\"\u0627\u0644\u062e\u0637\u0623:\", e)\n",
        "    # \u0647\u0646\u0627 \u0646\u062a\u0648\u0642\u0641 \u0644\u0623\u0646 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0641\u0639\u0644\u064a\u0627\u064b \u0644\u0627 \u064a\u0645\u0644\u0643 \u0645\u0644\u0641\u0627\u062a \u062a\u0634\u063a\u064a\u0644 \u0641\u064a \u0627\u0644\u0645\u0633\u062a\u0648\u062f\u0639\n",
        "    raise e\n",
        "\n",
        "print(\"\u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0645\u0639\u0627\u0644\u062c...\")\n",
        "# \u0627\u0644\u0645\u0639\u0627\u0644\u062c \u0623\u064a\u0636\u0627\u064b \u064a\u062d\u062a\u0627\u062c \u0644\u0646\u0633\u062e\u0629 \u0645\u062d\u062f\u062b\u0629\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=False)\n",
        "\n",
        "print(\"\u2705 \u062a\u0645 \u0627\u0644\u062a\u062d\u0645\u064a\u0644 \u0628\u0646\u062c\u0627\u062d!\")\n",
        "\n",
        "# ============================\n",
        "# \u062a\u062c\u0631\u0628\u0629 \u0633\u0631\u064a\u0639\u0629\n",
        "# ============================\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": [\n",
        "    {\"type\": \"image\", \"image\": image},\n",
        "    {\"type\": \"text\", \"text\": \"Describe this image.\"}\n",
        "]}]\n",
        "\n",
        "inputs = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=True, return_tensors=\"pt\", return_dict=True).to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=200)\n",
        "\n",
        "print(processor.decode(generated_ids[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "Yn2mUsKxW59R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "5bbd3c18-d053-48c1-d814-651c1909a4f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'partial_rotary_factor', 'mrope_section'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c (\u0645\u062d\u0627\u0648\u0644\u0629 \u0627\u0644\u062f\u0639\u0645 \u0627\u0644\u0623\u0635\u0644\u064a)...\n",
            "\u0641\u0634\u0644\u062a \u0627\u0644\u0645\u062d\u0627\u0648\u0644\u0629. \u064a\u0628\u062f\u0648 \u0623\u0646 \u062f\u0639\u0645 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0644\u0645 \u064a\u0635\u0644 \u0644\u0644\u0645\u0643\u062a\u0628\u0629 \u0627\u0644\u0631\u0626\u064a\u0633\u064a\u0629 \u0628\u0639\u062f.\n",
            "\u0627\u0644\u062e\u0637\u0623: Unrecognized configuration class <class 'transformers.models.glm4v.configuration_glm4v.Glm4vConfig'> for this kind of AutoModel: AutoModelForCausalLM.\n",
            "Model type should be one of AfmoeConfig, ApertusConfig, ArceeConfig, AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitNetConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, BltConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, CwmConfig, Data2VecTextConfig, DbrxConfig, DeepseekV2Config, DeepseekV3Config, DiffLlamaConfig, DogeConfig, Dots1Config, ElectraConfig, Emu3Config, ErnieConfig, Ernie4_5Config, Ernie4_5_MoeConfig, Exaone4Config, FalconConfig, FalconH1Config, FalconMambaConfig, FlexOlmoConfig, FuyuConfig, GemmaConfig, Gemma2Config, Gemma3Config, Gemma3TextConfig, Gemma3nConfig, Gemma3nTextConfig, GitConfig, GlmConfig, Glm4Config, Glm4MoeConfig, GotOcr2Config, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GptOssConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, GraniteMoeHybridConfig, GraniteMoeSharedConfig, HeliumConfig, HunYuanDenseV1Config, HunYuanMoEV1Config, JambaConfig, JetMoeConfig, Lfm2Config, Lfm2MoeConfig, LlamaConfig, Llama4Config, Llama4TextConfig, LongcatFlashConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegatronBertConfig, MiniMaxConfig, MinistralConfig, Ministral3Config, MistralConfig, MixtralConfig, MllamaConfig, ModernBertDecoderConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NanoChatConfig, NemotronConfig, OlmoConfig, Olmo2Config, Olmo3Config, OlmoeConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, Phi4MultimodalConfig, PhimoeConfig, PLBartConfig, ProphetNetConfig, Qwen2Config, Qwen2MoeConfig, Qwen3Config, Qwen3MoeConfig, Qwen3NextConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, SeedOssConfig, SmolLM3Config, StableLmConfig, Starcoder2Config, TrOCRConfig, VaultGemmaConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, xLSTMConfig, XmodConfig, ZambaConfig, Zamba2Config.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized configuration class <class 'transformers.models.glm4v.configuration_glm4v.Glm4vConfig'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of AfmoeConfig, ApertusConfig, ArceeConfig, AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitNetConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, BltConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, CwmConfig, Data2VecTextConfig, DbrxConfig, DeepseekV2Config, DeepseekV3Config, DiffLlamaConfig, DogeConfig, Dots1Config, ElectraConfig, Emu3Config, ErnieConfig, Ernie4_5Config, Ernie4_5_MoeConfig, Exaone4Config, FalconConfig, FalconH1Config, FalconMambaConfig, FlexOlmoConfig, FuyuConfig, GemmaConfig, Gemma2Config, Gemma3Config, Gemma3TextConfig, Gemma3nConfig, Gemma3nTextConfig, GitConfig, GlmConfig, Glm4Config, Glm4MoeConfig, GotOcr2Config, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GptOssConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, GraniteMoeHybridConfig, GraniteMoeSharedConfig, HeliumConfig, HunYuanDenseV1Config, HunYuanMoEV1Config, JambaConfig, JetMoeConfig, Lfm2Config, Lfm2MoeConfig, LlamaConfig, Llama4Config, Llama4TextConfig, LongcatFlashConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegatronBertConfig, MiniMaxConfig, MinistralConfig, Ministral3Config, MistralConfig, MixtralConfig, MllamaConfig, ModernBertDecoderConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NanoChatConfig, NemotronConfig, OlmoConfig, Olmo2Config, Olmo3Config, OlmoeConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, Phi4MultimodalConfig, PhimoeConfig, PLBartConfig, ProphetNetConfig, Qwen2Config, Qwen2MoeConfig, Qwen3Config, Qwen3MoeConfig, Qwen3NextConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, SeedOssConfig, SmolLM3Config, StableLmConfig, Starcoder2Config, TrOCRConfig, VaultGemmaConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, xLSTMConfig, XmodConfig, ZambaConfig, Zamba2Config.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3193174477.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\u0627\u0644\u062e\u0637\u0623:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# \u0647\u0646\u0627 \u0646\u062a\u0648\u0642\u0641 \u0644\u0623\u0646 \u0627\u0644\u0646\u0645\u0648\u0630\u062c \u0641\u0639\u0644\u064a\u0627\u064b \u0644\u0627 \u064a\u0645\u0644\u0643 \u0645\u0644\u0641\u0627\u062a \u062a\u0634\u063a\u064a\u0644 \u0641\u064a \u0627\u0644\u0645\u0633\u062a\u0648\u062f\u0639\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0645\u0639\u0627\u0644\u062c...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3193174477.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# \u0646\u062d\u0627\u0648\u0644 \u0627\u0644\u062a\u062d\u0645\u064a\u0644 \u0628\u062f\u0648\u0646 trust_remote_code \u0644\u0623\u0646 \u0627\u0644\u0645\u0644\u0641\u0627\u062a \u063a\u064a\u0631 \u0645\u0648\u062c\u0648\u062f\u0629\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# \u0627\u0644\u0645\u0643\u062a\u0628\u0629 \u0627\u0644\u0645\u062d\u062f\u062b\u0629 \u064a\u062c\u0628 \u0623\u0646 \u062a\u0639\u0631\u0641 Glm4vConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnb_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             )\n\u001b[0;32m--> 376\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;34mf\"Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.glm4v.configuration_glm4v.Glm4vConfig'> for this kind of AutoModel: AutoModelForCausalLM.\nModel type should be one of AfmoeConfig, ApertusConfig, ArceeConfig, AriaTextConfig, BambaConfig, BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BitNetConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, BltConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, Cohere2Config, CpmAntConfig, CTRLConfig, CwmConfig, Data2VecTextConfig, DbrxConfig, DeepseekV2Config, DeepseekV3Config, DiffLlamaConfig, DogeConfig, Dots1Config, ElectraConfig, Emu3Config, ErnieConfig, Ernie4_5Config, Ernie4_5_MoeConfig, Exaone4Config, FalconConfig, FalconH1Config, FalconMambaConfig, FlexOlmoConfig, FuyuConfig, GemmaConfig, Gemma2Config, Gemma3Config, Gemma3TextConfig, Gemma3nConfig, Gemma3nTextConfig, GitConfig, GlmConfig, Glm4Config, Glm4MoeConfig, GotOcr2Config, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GptOssConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, GraniteMoeHybridConfig, GraniteMoeSharedConfig, HeliumConfig, HunYuanDenseV1Config, HunYuanMoEV1Config, JambaConfig, JetMoeConfig, Lfm2Config, Lfm2MoeConfig, LlamaConfig, Llama4Config, Llama4TextConfig, LongcatFlashConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegatronBertConfig, MiniMaxConfig, MinistralConfig, Ministral3Config, MistralConfig, MixtralConfig, MllamaConfig, ModernBertDecoderConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NanoChatConfig, NemotronConfig, Olm..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# \u0633\u0646\u0633\u062a\u062e\u062f\u0645 \u0627\u0644\u0645\u0648\u062f\u064a\u0644 \u0627\u0644\u0631\u0633\u0645\u064a \u0628\u062f\u0644\u0627\u064b \u0645\u0646 zai-org \u0644\u0623\u0646\u0647 \u064a\u062d\u062a\u0648\u064a \u0639\u0644\u0649 \u0645\u0644\u0641\u0627\u062a \u0627\u0644\u062a\u0634\u063a\u064a\u0644 \u0627\u0644\u0635\u062d\u064a\u062d\u0629\n",
        "model_id = \"THUDM/glm-4v-9b\"\n",
        "\n",
        "print(\"1. \u0625\u0639\u062f\u0627\u062f \u062a\u0642\u0646\u064a\u0629 \u0627\u0644\u0636\u063a\u0637 (4-\u0628\u062a) \u0644\u064a\u0639\u0645\u0644 \u0639\u0644\u0649 T4...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "print(\"2. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c (\u0647\u0630\u0627 \u0633\u064a\u0623\u062e\u0630 \u0648\u0642\u062a\u0627\u064b \u0644\u0644\u062a\u062d\u0645\u064a\u0644 ~20 \u062c\u064a\u062c\u0627 \u0644\u0643\u0646 \u0633\u064a\u062d\u062c\u0632 6 \u062c\u064a\u062c\u0627 \u0631\u0627\u0645 \u0641\u0642\u0637)...\")\n",
        "# \u0627\u0644\u0645\u0648\u062f\u064a\u0644 \u0627\u0644\u0631\u0633\u0645\u064a \u064a\u062f\u0639\u0645 trust_remote_code \u0628\u0634\u0643\u0644 \u0635\u062d\u064a\u062d\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True, # \u0647\u0646\u0627 \u0633\u064a\u0639\u0645\u0644 \u0644\u0623\u0646\u0647 \u064a\u062d\u062a\u0648\u064a \u0639\u0644\u0649 \u0627\u0644\u0645\u0644\u0641\u0627\u062a\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "print(\"3. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0645\u062d\u0644\u0644 (Tokenizer)...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "print(\"\\n\u2705 \u062a\u0645 \u0627\u0644\u062a\u062d\u0645\u064a\u0644 \u0628\u0646\u062c\u0627\u062d! \u0627\u0644\u0645\u0648\u062f\u064a\u0644 \u062c\u0627\u0647\u0632.\")\n",
        "\n",
        "# ==========================================\n",
        "# \u062f\u0627\u0644\u0629 \u0644\u0644\u062a\u062d\u062f\u062b \u0645\u0639 \u0627\u0644\u0635\u0648\u0631\u0629\n",
        "# ==========================================\n",
        "def chat_with_image(image_url, prompt):\n",
        "    print(\"... \u062c\u0627\u0631\u064a \u0627\u0644\u0645\u0639\u0627\u0644\u062c\u0629 ...\")\n",
        "    image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "\n",
        "    # \u062a\u0646\u0633\u064a\u0642 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a \u062d\u0633\u0628 \u0637\u0631\u064a\u0642\u0629 GLM-4v\n",
        "    query = prompt\n",
        "    inputs = model.build_conversation_input_ids(\n",
        "        tokenizer,\n",
        "        query=query,\n",
        "        history=[],\n",
        "        images=[image]\n",
        "    )\n",
        "\n",
        "    inputs = {\n",
        "        'input_ids': inputs['input_ids'].unsqueeze(0).to('cuda'),\n",
        "        'token_type_ids': inputs['token_type_ids'].unsqueeze(0).to('cuda'),\n",
        "        'attention_mask': inputs['attention_mask'].unsqueeze(0).to('cuda'),\n",
        "        'images': [[inputs['images'][0].to('cuda').to(torch.float16)]]\n",
        "    }\n",
        "\n",
        "    gen_kwargs = {\"max_length\": 2500, \"do_sample\": True, \"top_k\": 1}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, **gen_kwargs)\n",
        "        outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
        "        response = tokenizer.decode(outputs[0])\n",
        "\n",
        "    return response.split(\"<|endoftext|>\")[0]\n",
        "\n",
        "# ==========================================\n",
        "# \u062a\u062c\u0631\u0628\u0629\n",
        "# ==========================================\n",
        "img_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "print(\"-\" * 30)\n",
        "print(chat_with_image(img_url, \"Describe this image in detail\"))"
      ],
      "metadata": {
        "id": "R_PGuvw4cYPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# \u0633\u0646\u0633\u062a\u062e\u062f\u0645 \u0627\u0644\u0645\u0648\u062f\u064a\u0644 \u0627\u0644\u0631\u0633\u0645\u064a \u0628\u062f\u0644\u0627\u064b \u0645\u0646 zai-org \u0644\u0623\u0646\u0647 \u064a\u062d\u062a\u0648\u064a \u0639\u0644\u0649 \u0645\u0644\u0641\u0627\u062a \u0627\u0644\u062a\u0634\u063a\u064a\u0644 \u0627\u0644\u0635\u062d\u064a\u062d\u0629\n",
        "model_id = \"THUDM/glm-4v-9b\"\n",
        "\n",
        "print(\"1. \u0625\u0639\u062f\u0627\u062f \u062a\u0642\u0646\u064a\u0629 \u0627\u0644\u0636\u063a\u0637 (4-\u0628\u062a) \u0644\u064a\u0639\u0645\u0644 \u0639\u0644\u0649 T4...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "print(\"1.5. \u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0648\u062a\u0639\u062f\u064a\u0644 \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0646\u0645\u0648\u0630\u062c...\")\n",
        "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
        "# Check if 'max_length' exists, if not, try to use 'seq_length'\n",
        "if not hasattr(config, 'max_length') and hasattr(config, 'seq_length'):\n",
        "    config.max_length = config.seq_length\n",
        "    print(f\"   \u062a\u0645 \u062a\u0639\u064a\u064a\u0646 config.max_length = config.seq_length ({config.max_length})\")\n",
        "elif not hasattr(config, 'max_length'):\n",
        "    # Fallback or set a default if neither is found.\n",
        "    # A reasonable default for GLM models might be 2048 or 4096.\n",
        "    config.max_length = 2048 # A common default if seq_length is also missing\n",
        "    print(f\"   \u0644\u0645 \u064a\u062a\u0645 \u0627\u0644\u0639\u062b\u0648\u0631 \u0639\u0644\u0649 max_length \u0623\u0648 seq_length\u060c \u062a\u0645 \u062a\u0639\u064a\u064a\u0646 config.max_length \u0625\u0644\u0649 {config.max_length} \u0643\u0642\u064a\u0645\u0629 \u0627\u0641\u062a\u0631\u0627\u0636\u064a\u0629.\")\n",
        "\n",
        "\n",
        "print(\"2. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c (\u0647\u0630\u0627 \u0633\u064a\u0623\u062e\u0630 \u0648\u0642\u062a\u0627\u064b \u0644\u0644\u062a\u062d\u0645\u064a\u0644 ~20 \u062c\u064a\u062c\u0627 \u0644\u0643\u0646 \u0633\u064a\u062d\u062c\u0632 6 \u062c\u064a\u062c\u0627 \u0631\u0627\u0645 \u0641\u0642\u0637)...\")\n",
        "# \u0627\u0644\u0645\u0648\u062f\u064a\u0644 \u0627\u0644\u0631\u0633\u0645\u064a \u064a\u062f\u0639\u0645 trust_remote_code \u0628\u0634\u0643\u0644 \u0635\u062d\u064a\u062d\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    config=config, # Pass the modified config\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True, # \u0647\u0646\u0627 \u0633\u064a\u0639\u0645\u0644 \u0644\u0623\u0646\u0647 \u064a\u062d\u062a\u0648\u064a \u0639\u0644\u0649 \u0627\u0644\u0645\u0644\u0641\u0627\u062a\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "print(\"3. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0645\u062d\u0644\u0644 (Tokenizer)...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "print(\"\\n\u2705 \u062a\u0645 \u0627\u0644\u062a\u062d\u0645\u064a\u0644 \u0628\u0646\u062c\u0627\u062d! \u0627\u0644\u0645\u0648\u062f\u064a\u0644 \u062c\u0627\u0647\u0632.\")\n",
        "\n",
        "# ==========================================\n",
        "# \u062f\u0627\u0644\u0629 \u0644\u0644\u062a\u062d\u062f\u062b \u0645\u0639 \u0627\u0644\u0635\u0648\u0631\u0629\n",
        "# ==========================================\n",
        "def chat_with_image(image_url, prompt):\n",
        "    print(\"... \u062c\u0627\u0631\u064a \u0627\u0644\u0645\u0639\u0627\u0644\u062c\u0629 ...\")\n",
        "    image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "\n",
        "    # \u062a\u0646\u0633\u064a\u0642 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a \u062d\u0633\u0628 \u0637\u0631\u064a\u0642\u0629 GLM-4v\n",
        "    query = prompt\n",
        "    inputs = model.build_conversation_input_ids(\n",
        "        tokenizer,\n",
        "        query=query,\n",
        "        history=[],\n",
        "        images=[image]\n",
        "    )\n",
        "\n",
        "    inputs = {\n",
        "        'input_ids': inputs['input_ids'].unsqueeze(0).to(model.device),\n",
        "        'token_type_ids': inputs['token_type_ids'].unsqueeze(0).to(model.device),\n",
        "        'attention_mask': inputs['attention_mask'].unsqueeze(0).to(model.device),\n",
        "        'images': [[inputs['images'][0].to(model.device).to(torch.float16)]]\n",
        "    }\n",
        "\n",
        "    #gen_kwargs = {\"max_length\": 2500, \"do_sample\": True, \"top_k\": 1}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, **gen_kwargs)\n",
        "        outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
        "        response = tokenizer.decode(outputs[0])\n",
        "\n",
        "    return response.split(\"<|endoftext|>\")[0]\n",
        "\n",
        "# ==========================================\n",
        "# \u062a\u062c\u0631\u0628\u0629\n",
        "# ==========================================\n",
        "img_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "print(\"-\" * 30)\n",
        "print(chat_with_image(img_url, \"Describe this image in detail\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjc5xX47ZzNq",
        "outputId": "6584de99-ced1-4a24-a7ba-57a76dec672b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. \u0625\u0639\u062f\u0627\u062f \u062a\u0642\u0646\u064a\u0629 \u0627\u0644\u0636\u063a\u0637 (4-\u0628\u062a) \u0644\u064a\u0639\u0645\u0644 \u0639\u0644\u0649 T4...\n",
            "1.5. \u062c\u0627\u0631\u064a \u062a\u062d\u0645\u064a\u0644 \u0648\u062a\u0639\u062f\u064a\u0644 \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u0646\u0645\u0648\u0630\u062c...\n",
            "   \u062a\u0645 \u062a\u0639\u064a\u064a\u0646 config.max_length = config.seq_length (8192)\n",
            "2. \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0646\u0645\u0648\u0630\u062c (\u0647\u0630\u0627 \u0633\u064a\u0623\u062e\u0630 \u0648\u0642\u062a\u0627\u064b \u0644\u0644\u062a\u062d\u0645\u064a\u0644 ~20 \u062c\u064a\u062c\u0627 \u0644\u0643\u0646 \u0633\u064a\u062d\u062c\u0632 6 \u062c\u064a\u062c\u0627 \u0631\u0627\u0645 \u0641\u0642\u0637)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoProcessor, Glm4vForConditionalGeneration, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "# \u0627\u0633\u062a\u062e\u062f\u0645 AutoProcessor (\u0623\u0648 \u0645\u0639\u0627\u0644\u062c \u0645\u062e\u0635\u0635 \u0625\u0630\u0627 \u0645\u062a\u0648\u0641\u0631) \u0644\u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0635\u0648\u0631\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "model = Glm4vForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "# \u0645\u062b\u0627\u0644: \u062a\u0632\u0648\u064a\u062f \u0646\u0645\u0648\u0630\u062c \u0628\u0635\u0648\u0631\u0629 + \u0633\u0624\u0627\u0644\n",
        "inputs = processor(\n",
        "    images=[\"/content/images.webp\"],   # \u0623\u0648 \u0642\u0627\u0626\u0645\u0629 \u0645\u0646 \u0627\u0644\u0635\u0648\u0631\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \u0627\u0644\u0645\u062d\u062a\u0648\u0649 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u0648\u0633\u0627\u0626\u0637: \u0627\u0644\u0635\u0648\u0631\u0629 + \u0627\u0644\u0646\u0635\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"url\": None,  # \u0644\u0623\u0646\u0646\u0627 \u062a\u0645\u0631\u0631 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u0628\u0627\u0634\u0631\u0629 \u0648\u0644\u064a\u0633 URL\n",
        "                \"image\": inputs.pixel_values  # \u0623\u0648 \u0627\u0644\u062d\u0642\u0644 \u0627\u0644\u0645\u0646\u0627\u0633\u0628 \u0645\u0646 processor\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"Describe this picture in detail, and mention the main elements.\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# \u062b\u0645 \u062a\u0645\u0631\u064a\u0631 \u0627\u0644\u0631\u0633\u0627\u0626\u0644 \u0625\u0644\u0649 \u0627\u0644\u0646\u0645\u0648\u0630\u062c\n",
        "outputs = model.generate(**inputs, prompt=messages)  # \u0635\u064a\u063a\u0629 \u062a\u0642\u0631\u064a\u0628\u064a\u0629 \u2014 \u0628\u062d\u0633\u0628 API \u0627\u0644\u062f\u0627\u062e\u0644\u064a \u0644\u0644\u0646\u0645\u0648\u0630\u062c\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "0dRnmsQtdWbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoProcessor, Glm4vForConditionalGeneration, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "# \u0627\u0633\u062a\u062e\u062f\u0645 AutoProcessor (\u0623\u0648 \u0645\u0639\u0627\u0644\u062c \u0645\u062e\u0635\u0635 \u0625\u0630\u0627 \u0645\u062a\u0648\u0641\u0631) \u0644\u0645\u0639\u0627\u0644\u062c\u0629 \u0627\u0644\u0635\u0648\u0631\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "model = Glm4vForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "# \u0645\u062b\u0627\u0644: \u062a\u0632\u0648\u064a\u062f \u0646\u0645\u0648\u0630\u062c \u0628\u0635\u0648\u0631\u0629 + \u0633\u0624\u0627\u0644\n",
        "inputs = processor(\n",
        "    images=[\"/content/images.webp\"],   # \u0623\u0648 \u0642\u0627\u0626\u0645\u0629 \u0645\u0646 \u0627\u0644\u0635\u0648\u0631\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \u0627\u0644\u0645\u062d\u062a\u0648\u0649 \u0645\u062a\u0639\u062f\u062f \u0627\u0644\u0648\u0633\u0627\u0626\u0637: \u0627\u0644\u0635\u0648\u0631\u0629 + \u0627\u0644\u0646\u0635\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"url\": None,  # \u0644\u0623\u0646\u0646\u0627 \u062a\u0645\u0631\u0631 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u0628\u0627\u0634\u0631\u0629 \u0648\u0644\u064a\u0633 URL\n",
        "                \"image\": inputs.pixel_values  # \u0623\u0648 \u0627\u0644\u062d\u0642\u0644 \u0627\u0644\u0645\u0646\u0627\u0633\u0628 \u0645\u0646 processor\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"Describe this picture in detail, and mention the main elements.\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# \u062b\u0645 \u062a\u0645\u0631\u064a\u0631 \u0627\u0644\u0631\u0633\u0627\u0626\u0644 \u0625\u0644\u0649 \u0627\u0644\u0646\u0645\u0648\u0630\u062c\n",
        "outputs = model.generate(**inputs, prompt=messages)  # \u0635\u064a\u063a\u0629 \u062a\u0642\u0631\u064a\u0628\u064a\u0629 \u2014 \u0628\u062d\u0633\u0628 API \u0627\u0644\u062f\u0627\u062e\u0644\u064a \u0644\u0644\u0646\u0645\u0648\u0630\u062c\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634,
          "referenced_widgets": [
            "34548dd61d8d431dbfcbe13386d04dd1",
            "b308f9cc273f424f8126c29b462802c3",
            "dcbdda757de54d24916b2a070e7c84f6",
            "7e85b9e9497440f5badf2db457add507",
            "5bde41b8d72a4a699268192940f34a37",
            "e354836e88d14ca38b6b7c1b080f3be7",
            "f08b6ee0d57e41cb992f70c418fc8027",
            "b007f0c113ad4107be4a21c82863e6b2",
            "f9d5a24db5874c45850887784a8ae6bf",
            "093cc0035f274544967e0c5dac39ca1a",
            "59d7e0542a82420e8d9c7bc92314015f",
            "44b5a935b1c84e37879c1dd8f895c8a2",
            "70fd570ad6754ad4afd52e3e0a699c72",
            "89561aeff3704f29b432a43d8eef89a3",
            "5f0c7161b1684ef48461246a50625ec2",
            "b7db2ac157454ff6ac0624af6633ec7c",
            "c53a077d0f3042f0bc269b3a79629619",
            "bead5e5f5f39436d858b9f433a8996eb",
            "68aa9045ce7b4ad08206e89a9c34131c",
            "cb96e4e7fbb04fe185e4eba1754147ca",
            "fc6ea1f93020432c9926f42e1313b9b8",
            "7b4da710d0244acb9df6b4dc1a660049",
            "27f794a94bc54303941120adf42649a9",
            "03cbaf728e074cae835fec511569328a",
            "15d815f08fdf4a26b318ed6457e3778f",
            "b6176490b0ce42c280f42427530a97f9",
            "a7c4b75ed7dc4e158dcb4199a602eee1",
            "a51cdf920eb344df86f94ab99808dadd",
            "836f9bdd49334dea889ad170e261796c",
            "3ea270d496ff43b4bde27b575128b25a",
            "5be766b26e984b2c84dab2d4cf59b4ec",
            "0c23f56590fc433ab25df95846d8a88f",
            "2f36530a9a1c43a093049d96642cd9ab",
            "6ab7b74f90ab4cc9adcbf561f8fdaec9",
            "3b94fcc4fac643748379030cc3d4b210",
            "01dea2f9aef64e37af5c5299f29597c4",
            "749a6e3b731b44a69fe38e2aa00ca9ad",
            "5d7cf5f57021470cacc79eef34adecce",
            "b68f367c415f433282a03bc478995230",
            "97c6fd5a7b0b42109be4f8ae4509c2ac",
            "84c0fae2621a49648b11bc84d9d6bd18",
            "e006836fc08e4ecd92519c7b0cc04bc6",
            "7517b59d4a024640bffaf99a10655ec1",
            "78fae2466e1749c89e58a28117640290",
            "43e50add2bf843769de00c43d93c0cf0",
            "ea064d51d82448e6b2306d0997c5506d",
            "055ae97bee104654b53efbf66b4954fe",
            "9fc472037afe47199dd6696c594248d7",
            "f4adb4a2c20c4213beb675b3c9537b83",
            "d70392bfec9a4e1ab85e373c57055466",
            "21bd75cfa0d149948bc67df19f760d06",
            "1100f9203aa843ce9f186ef9216a66cd",
            "7a772cd72f284cdb83faf05caadcede5",
            "900122bf10cf404cbf363ff2a9370eed",
            "c80c3a5c4b2a48eda0d9f9ac694b8da6",
            "d8d33521fce2465cbcb98a05d39bb3f4",
            "e6efc5c915e4459f998996601a410966",
            "935d82772b1e4ccea7a2d236fd229b93",
            "0a484f5783a645d891ff2df6b2e11592",
            "4703bccd58b94d9b8ec5b299a5dd902e",
            "8517db50a38943a3a5c633d1e188baec",
            "3d5a72e7cb7f486d8c6e09eebb5c748f",
            "98971afd0fcf44e49b00208f30a239ca",
            "5135520edc124e2db151401cc3c192d3",
            "9e8ad4f00e0c439f96de2cc14d45a1b8",
            "afe36399b4544203b024b9ac058e342e"
          ]
        },
        "id": "jxndwqTDaboR",
        "outputId": "99e595fa-130d-4075-db6c-c23a689a72e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34548dd61d8d431dbfcbe13386d04dd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "video_preprocessor_config.json:   0%|          | 0.00/369 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44b5a935b1c84e37879c1dd8f895c8a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'partial_rotary_factor', 'mrope_section'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27f794a94bc54303941120adf42649a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ab7b74f90ab4cc9adcbf561f8fdaec9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/704 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43e50add2bf843769de00c43d93c0cf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8d33521fce2465cbcb98a05d39bb3f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "argument of type 'NoneType' is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2686562907.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# \u0645\u062b\u0627\u0644: \u062a\u0632\u0648\u064a\u062f \u0646\u0645\u0648\u0630\u062c \u0628\u0635\u0648\u0631\u0629 + \u0633\u0624\u0627\u0644\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m inputs = processor(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/content/images.webp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# \u0623\u0648 \u0642\u0627\u0626\u0645\u0629 \u0645\u0646 \u0627\u0644\u0635\u0648\u0631\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/glm46v/processing_glm46v.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, images, text, videos, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_token\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                     \u001b[0mnum_image_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_grid_thw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmerge_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                     \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<|placeholder|>\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_image_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, Glm4vForConditionalGeneration\n",
        "\n",
        "MODEL_PATH = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "model = Glm4vForConditionalGeneration.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16  # \u0623\u0648 \"auto\"\n",
        ")\n",
        "\n",
        "# \u0645\u062b\u0627\u0644: \u0635\u0648\u0631\u0629 + \u0633\u0624\u0627\u0644\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"url\": \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"\u0635\u0641 \u0647\u0630\u0647 \u0627\u0644\u0635\u0648\u0631\u0629 \u0628\u0627\u0644\u062a\u0641\u0635\u064a\u0644 \u0648\u0627\u0630\u0643\u0631 \u0627\u0644\u0645\u0643\u0648\u0646\u0627\u062a \u0627\u0644\u0638\u0627\u0647\u0631\u0629.\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "\n",
        "inputs.pop(\"token_type_ids\", None)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=51,\n",
        "    do_sample=False\n",
        ")\n",
        "\n",
        "output = processor.decode(\n",
        "    generated_ids[0][inputs[\"input_ids\"].shape[1]:],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "hOBB7dpXdy3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UxpyjoRbeWg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig, AutoProcessor, Glm4vForConditionalGeneration\n",
        "\n",
        "MODEL_PATH = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u062a\u0643\u0645\u064a\u0645 4-\u0628\u062a\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "\n",
        "model = Glm4vForConditionalGeneration.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \"\u0645\u062d\u0627\u062f\u062b\u0629\" \u062a\u062d\u062a\u0648\u064a \u0635\u0648\u0631\u0629 + \u0633\u0624\u0627\u0644\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"url\": \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"Describe this image in detail.\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# \u062a\u0623\u0643\u062f \u0623\u0646 \u0643\u0644 \u0627\u0644\u062a\u064a\u0646\u0633\u0648\u0631\u0632 \u0639\u0644\u0649 \u0646\u0641\u0633 \u0627\u0644\u062c\u0647\u0627\u0632\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "inputs.pop(\"token_type_ids\", None)\n",
        "\n",
        "# \u062a\u0648\u0644\u064a\u062f\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=51)\n",
        "\n",
        "# \u0641\u0643 \u0627\u0644\u062a\u0634\u0641\u064a\u0631\n",
        "output = processor.decode(\n",
        "    generated_ids[0][inputs[\"input_ids\"].shape[1]:],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544,
          "referenced_widgets": [
            "dff55b09a50146aebd75e7b9bc1175fe",
            "28516c07b96740b78c9cb92f7909261d",
            "8cc8cf870bda439c8770c4e64c30e92a",
            "7e5cf691bcd040afa316a3289e3d6623",
            "59f80af631a549e7a4cddffc669c69b4",
            "2f76cbc756364b3d997be1848fc42ddf",
            "76bfa0c0cdfb41f9b284e696a8fc3ce6",
            "0eb2f49e1b1342eaa1cb2fc4e7542df3",
            "cae42f5a279446168e0481d5ae1d6ad5",
            "62dbe71f0b174a8aa73f0153c05560b6",
            "9d17232721bb47d4a318975a303a2223",
            "20ade25d2695486f9fc962ebcc5d6365",
            "a43813251ad24076a6d5ab657f3affa6",
            "acd2db24d5e146a8905c8b784ae50c0c",
            "eb7b7b42d90648269ab4e1e715aea304",
            "86bfe94e4f6b480996f4c9b730778e0e",
            "ee9d2ff484eb4a49b2e49e5f5682bb3e",
            "8635a0cd5ee04a309bd309c0feb20ef0",
            "fbad5f0f718547a8b562b86b710adbde",
            "0deaa8c996c4476c87c41ad3dfae46bc",
            "836b62c534844d85b554975bb4b8ff3d",
            "f5dccfe0a6cc4c4cb21276b85d9921e6",
            "084966703efd4396913514eb9746929f",
            "c0f43de2e1624be590e5365bd94f9864",
            "3e6c29e1c297438cb471bb03a78c35cc",
            "9a8952585b5f46ed9141c80b7e4ec7d7",
            "8f7c2d5049c34003b479a87ac284a01e",
            "3e4939ca28e84e8ea254b658985b13c7",
            "da82d100200845bbb0d395b4f3c3e18d",
            "bcd7c7e9a089400c9c4fc99019c188f8",
            "d43ee52801b24984a5d930791c681501",
            "f97e10ca97c84681829157a53f33bacd",
            "01c9ca19d2f34abe862f3311913dbd1a"
          ]
        },
        "id": "T1FUgxyCeWdZ",
        "outputId": "b7ccaed6-d3d7-421d-a862-bea3036bb303"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'mrope_section', 'partial_rotary_factor'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dff55b09a50146aebd75e7b9bc1175fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20ade25d2695486f9fc962ebcc5d6365"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/704 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "084966703efd4396913514eb9746929f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "cannot identify image file <_io.BytesIO object at 0x7b80473a20c0>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-310690109.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m ]\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m inputs = processor.apply_chat_template(\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36mapply_chat_template\u001b[0;34m(self, conversation, chat_template, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0mimages_exist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_images\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mim_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m             \u001b[0mvideos_exist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvid_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_videos\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvid_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m             out = self(\n\u001b[0m\u001b[1;32m   1738\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_images\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimages_exist\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/glm46v/processing_glm46v.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, images, text, videos, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m         )\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mimage_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moutput_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mimage_grid_thw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_grid_thw\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_processing_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, images, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImageInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnpack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImagesKwargs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;34m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/glm46v/image_processing_glm46v.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, images, do_resize, size, resample, do_rescale, rescale_factor, do_normalize, image_mean, image_std, patch_size, temporal_patch_size, merge_size, do_convert_rgb, return_tensors, data_format, input_data_format)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_flat_list_of_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_processing_base.py\u001b[0m in \u001b[0;36mfetch_images\u001b[0;34m(self, image_url_or_urls)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_processing_base.py\u001b[0m in \u001b[0;36mfetch_images\u001b[0;34m(self, image_url_or_urls)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_processing_base.py\u001b[0m in \u001b[0;36mfetch_images\u001b[0;34m(self, image_url_or_urls)\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_valid_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage_url_or_urls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(image, timeout)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# We need to actually check for a real protocol, otherwise it's impossible to use a local file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# like http_huggingface_co.png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3578\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3579\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3580\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnidentifiedImageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7b80473a20c0>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tc1EZ82TfKgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig, AutoProcessor, Glm4vForConditionalGeneration\n",
        "\n",
        "MODEL_PATH = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f\u0627\u062a \u0627\u0644\u062a\u0643\u0645\u064a\u0645 4-\u0628\u062a\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "\n",
        "model = Glm4vForConditionalGeneration.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \"\u0645\u062d\u0627\u062f\u062b\u0629\" \u062a\u062d\u062a\u0648\u064a \u0635\u0648\u0631\u0629 + \u0633\u0624\u0627\u0644\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "                \"type\": \"image\",\n",
        "                \"url\": \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": \"Describe this image in detail.\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# \u062a\u0623\u0643\u062f \u0623\u0646 \u0643\u0644 \u0627\u0644\u062a\u064a\u0646\u0633\u0648\u0631\u0632 \u0639\u0644\u0649 \u0646\u0641\u0633 \u0627\u0644\u062c\u0647\u0627\u0632\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "inputs.pop(\"token_type_ids\", None)\n",
        "\n",
        "# \u062a\u0648\u0644\u064a\u062f\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=51)\n",
        "\n",
        "# \u0641\u0643 \u0627\u0644\u062a\u0634\u0641\u064a\u0631\n",
        "output = processor.decode(\n",
        "    generated_ids[0][inputs[\"input_ids\"].shape[1]:],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "Rmy0hM92fMFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image as IPImage\n",
        "image_path = \"/home/Ubuntu/images/lane.png\"\n",
        "image = load_image(image_path)\n",
        "\n",
        "prompt = \"\"\"\n",
        "Which lane is open?\n",
        "\"\"\"\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": image}, {\"type\": \"text\", \"text\": prompt}],}]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "inputs.pop(\"token_type_ids\", None)\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=8192)\n",
        "output_text = processor.decode(generated_ids[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=False)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "Osoc4riwfdS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, GLM4vMoeForConditionalGeneration\n",
        "import torch\n",
        "from transformers.image_utils import load_image\n",
        "from IPython.display import display, Image as IPImage\n",
        "\n",
        "MODEL_PATH = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH)\n",
        "model = GLM4vMoeForConditionalGeneration.from_pretrained(\n",
        "    pretrained_model_name_or_path=MODEL_PATH,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "from IPython.display import display, Image as IPImage\n",
        "image_path = \"/home/Ubuntu/images/lane.png\"\n",
        "image = load_image(image_path)\n",
        "\n",
        "prompt = \"\"\"\n",
        "Which lane is open?\n",
        "\"\"\"\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": image}, {\"type\": \"text\", \"text\": prompt}],}]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_dict=True,\n",
        "    return_tensors=\"pt\"\n",
        ").to(model.device)\n",
        "inputs.pop(\"token_type_ids\", None)\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=8192)\n",
        "output_text = processor.decode(generated_ids[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=False)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "trry7x95fY2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1kwK56XZfnkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rwkh_X08fniR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig, AutoProcessor, Glm4vForConditionalGeneration\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "MODEL_PATH = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f 4-\u0628\u062a\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "\n",
        "model = Glm4vForConditionalGeneration.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# \u062a\u062d\u0645\u064a\u0644 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u0646 URL \u0648\u0641\u062a\u062d\u0647\u0627 \u0628\u0640 PIL\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\n",
        "resp = requests.get(url, stream=True)\n",
        "resp.raise_for_status()\n",
        "image = Image.open(BytesIO(resp.content)).convert(\"RGB\")\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \u0627\u0644\u0631\u0633\u0627\u0644\u0629 (\u0635\u0648\u0631\u0629 + \u0646\u0635)\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# \u062a\u062c\u0647\u064a\u0632 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a \u0645\u0639 \u0627\u0644\u0635\u0648\u0631\u0629\n",
        "chat_template = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "inputs = processor(text=chat_template, images=[image], return_tensors=\"pt\")\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "inputs.pop(\"token_type_ids\", None)\n",
        "\n",
        "# \u062a\u0648\u0644\u064a\u062f\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=512)\n",
        "\n",
        "output = processor.decode(generated_ids[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538,
          "referenced_widgets": [
            "23b5f55f5ee840f0a5361b621d668a12",
            "e7bb1e55b25d445383743c03930876dc",
            "051f77f909cd447b97814509a9d62128",
            "45fd5a5f308048bc8292b73aa4d88f3f",
            "f024cc14bfa2490fb4bfbc76abd804d9",
            "7d9664defbb3439da80cee015b429df1",
            "17631b7b59d646feb6c360e46bd5fac6",
            "5e6210bc5af24be995df032cf746a800",
            "b81fee330358448da146c34702b23452",
            "f5df739292f84cb0a5fb2e540cecf62b",
            "c8740ddf32d84b3e9221d306fd31c3e6",
            "e082486cb89d4a768ea33b10898321fc",
            "76022962dcad4823a2bf65b59ecdb175",
            "c1cdd34a5e4d4dc4af3d11e388d6a9d6",
            "cf1fcfc92d444bf59d9f2feb0c50a417",
            "1637abeaeb98407ead01973950cc2fba",
            "df3bf86073a748f39c5229044bd394d4",
            "aebd40a8b7a0413cb6377f2416a254ef",
            "4781fa09c43b44ab88f17e1cf5ff1009",
            "b39156911a6a445f8c482034ba52a3c3",
            "2b12f6601dd1414bbf82a180ff0247c4",
            "5b6a5efe6edd4dbdb19d5abeb7afd9b9",
            "30666c8534cc49a3b1c92014e478393a",
            "ea3017d085624514b1f027e84611280e",
            "5f74b552a0ed49e4850d1e9d26f3c066",
            "cbd3accf8f20499e97bc9bc4d9aa5a6f",
            "2b8a732d13694a9ea9f636ca71e07be9",
            "c787f44919494499af3420231384cb5d",
            "2caae2fe8f3c4ba5868a829e4e725fe6",
            "187b51ee2aee425fa35f1e9dbdbc81ee",
            "22ca5b4a816948619d0522995c78c532",
            "f774349e15794a7a87925daad7675743",
            "e9d1543ff97740d1916e4f23b92a3014"
          ]
        },
        "id": "10-gVK-Sfnen",
        "outputId": "9d425cb0-df7b-425a-9125-19abccc016af"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'mrope_section', 'partial_rotary_factor'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23b5f55f5ee840f0a5361b621d668a12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e082486cb89d4a768ea33b10898321fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/704 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30666c8534cc49a3b1c92014e478393a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "403 Client Error: Forbidden for url: https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-824914897.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://upload.wikimedia.org/wikipedia/commons/f/fa/Grayscale_8bits_palette_sample_image.png"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7_tQXeUbhOpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5-r7WVXihOle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dAfBCnf0hOiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \u0634\u063a\u0627\u0644"
      ],
      "metadata": {
        "id": "uir-my2ZiRlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig, AutoProcessor, Glm4vForConditionalGeneration\n",
        "from PIL import Image\n",
        "\n",
        "MODEL_PATH = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \u0636\u063a\u0637 4-\u0628\u062a\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "\n",
        "model = Glm4vForConditionalGeneration.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# --- \u0627\u0642\u0631\u0623 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u0646 \u0645\u0644\u0641 \u0645\u062d\u0644\u064a ---\n",
        "image_path = \"/content/Grayscale_8bits_palette_sample_image.png\"   # \u0639\u062f\u0651\u0650\u0644 \u0647\u0630\u0627 \u0625\u0644\u0649 \u0645\u0633\u0627\u0631 \u0627\u0644\u0635\u0648\u0631\u0629 \u0639\u0646\u062f\u0643\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \u0631\u0633\u0627\u0644\u0629: \u0635\u0648\u0631\u0629 + \u0646\u0635\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            # \u0644\u0646 \u062a\u062d\u062a\u0627\u062c url \u0644\u0623\u0646 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u062d\u0644\u064a\u0651\u0629\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "# \u062a\u062c\u0647\u064a\u0632 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a: \u0627\u0644\u0635\u0648\u0631 + \u0627\u0644\u0646\u0635\n",
        "chat_template = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "inputs = processor(\n",
        "    text=chat_template,\n",
        "    images=[image],\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# \u0646\u0642\u0644 \u0627\u0644\u062a\u064a\u0646\u0633\u0648\u0631\u0627\u062a \u0625\u0644\u0649 \u0646\u0641\u0633 \u062c\u0647\u0627\u0632 \u0627\u0644\u0646\u0645\u0648\u0630\u062c (GPU \u0623\u0648 CPU)\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "inputs.pop(\"token_type_ids\", None)\n",
        "\n",
        "# \u062a\u0648\u0644\u064a\u062f \u0627\u0644\u0646\u0635 (\u0627\u0644\u0648\u0635\u0641)\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=51)\n",
        "\n",
        "output = processor.decode(\n",
        "    generated_ids[0][ inputs[\"input_ids\"].shape[1]: ],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "99d9ca72235847bc9ceb6e459a879dc7",
            "64fa4dd9a818466d8d55fb4a331a6de2",
            "bb436d37d11842388fd21aec0aa7f012",
            "e3025cba5ab04f59b026c01d27812129",
            "b574811b43824e7c9925d80e65baf5e4",
            "08ed536841e04c949e2e2bf0de4ab8cc",
            "f119385f18f24a04a94070d9981ca72b",
            "273d7a6261e3442ea4f7bcbdd7e5aed5",
            "60163e60096c4b8ab26dec239a6fa32e",
            "ed92613d10294b0d865c68e65ae4b650",
            "9e3a623a4c2a4cfaa6ff42637d765344",
            "7ed2e32089d04c0f8e98d3942ffb8e95",
            "b43da50818184c098e739e1a07425a0c",
            "9ff3ec2903154da592e5c8a2a5462961",
            "d569308f2cbc467883b492da8b6392bb",
            "73b6c09b2ec34cf89c6632af47edc9d3",
            "c7d31d8816f6437bba2b35f60482c0a3",
            "278000772da0495faa81b25e48fc8580",
            "c0317147100d40ffb65358f28d5a99fc",
            "dc792e482ae74b7a8e6bf84d4d7d5af8",
            "7e8b56ca8e3b489e80f73b7f540ef5ca",
            "8b5eba58edb3402ca4e28d3406f4893a",
            "6a506dfb7fec4aa0945ef9a311de970e",
            "5d9e455e121a405a830bbaee10e1428c",
            "b23874f35fed4ca7a51a6f58fd526f37",
            "9de1d96496004ad8803b8d991ae80e9f",
            "01b3e036c66f4ac1a40951d812387b59",
            "c7078438933043dd8215dff2272ae88d",
            "8685e41645ac4187a8d457ff20e131f6",
            "ddee837eecdc4f9fb231ae119509d7e2",
            "cb2c3ebf9a3942d1a143b415ab67f11c",
            "9953d1a9a32541e8a704bfa9c41c7869",
            "d75a34cfbea84bc1bf066adf179d8ee9"
          ]
        },
        "id": "xQvlCafdhOb1",
        "outputId": "de359d3e-05a5-4429-bcac-a1152826a391"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Unrecognized keys in `rope_parameters` for 'rope_type'='default': {'partial_rotary_factor', 'mrope_section'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99d9ca72235847bc9ceb6e459a879dc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ed2e32089d04c0f8e98d3942ffb8e95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/704 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a506dfb7fec4aa0945ef9a311de970e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>Got it, let's describe this black-and-white image of a parrot. First, the main subject is a parrot, likely a macaw or similar species, with a prominent crest on its head. The parrot is perched on a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<think>\u0641\u0647\u0645\u062a\u060c \u062f\u0639\u0646\u0627 \u0646\u0635\u0641 \u0647\u0630\u0647 \u0627\u0644\u0635\u0648\u0631\u0629 \u0628\u0627\u0644\u0623\u0628\u064a\u0636 \u0648\u0627\u0644\u0623\u0633\u0648\u062f \u0644\u0644\u0628\u0628\u063a\u0627\u0621. \u0623\u0648\u0644\u0627\u064b\u060c \u0627\u0644\u0645\u0648\u0636\u0648\u0639 \u0627\u0644\u0631\u0626\u064a\u0633\u064a \u0647\u0648 \u0628\u0628\u063a\u0627\u0621\u060c \u0639\u0644\u0649 \u0627\u0644\u0623\u0631\u062c\u062d \u0645\u0646 \u0646\u0648\u0639 \u0627\u0644\u0645\u0643\u0627\u0648 \u0623\u0648 \u0646\u0648\u0639 \u0645\u0634\u0627\u0628\u0647\u060c \u0648\u0644\u0647 \u0639\u0631\u0641 \u0628\u0627\u0631\u0632 \u0639\u0644\u0649 \u0631\u0623\u0633\u0647. \u0627\u0644\u0628\u0628\u063a\u0627\u0621 \u062c\u0627\u062b\u0645 \u0639\u0644\u0649"
      ],
      "metadata": {
        "id": "ZmvHRqa-ijSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig, AutoProcessor, Glm4vForConditionalGeneration\n",
        "from PIL import Image\n",
        "\n",
        "MODEL_PATH = \"zai-org/GLM-4.6V-Flash\"\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \u0636\u063a\u0637 4-\u0628\u062a\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "\n",
        "model = Glm4vForConditionalGeneration.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# --- \u0627\u0642\u0631\u0623 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u0646 \u0645\u0644\u0641 \u0645\u062d\u0644\u064a ---\n",
        "image_path = \"/content/Grayscale_8bits_palette_sample_image.png\"   # \u0639\u062f\u0651\u0650\u0644 \u0647\u0630\u0627 \u0625\u0644\u0649 \u0645\u0633\u0627\u0631 \u0627\u0644\u0635\u0648\u0631\u0629 \u0639\u0646\u062f\u0643\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# \u0625\u0639\u062f\u0627\u062f \u0631\u0633\u0627\u0644\u0629: \u0635\u0648\u0631\u0629 + \u0646\u0635\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            # \u0644\u0646 \u062a\u062d\u062a\u0627\u062c url \u0644\u0623\u0646 \u0627\u0644\u0635\u0648\u0631\u0629 \u0645\u062d\u0644\u064a\u0651\u0629\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "# \u062a\u062c\u0647\u064a\u0632 \u0627\u0644\u0645\u062f\u062e\u0644\u0627\u062a: \u0627\u0644\u0635\u0648\u0631 + \u0627\u0644\u0646\u0635\n",
        "chat_template = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "inputs = processor(\n",
        "    text=chat_template,\n",
        "    images=[image],\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# \u0646\u0642\u0644 \u0627\u0644\u062a\u064a\u0646\u0633\u0648\u0631\u0627\u062a \u0625\u0644\u0649 \u0646\u0641\u0633 \u062c\u0647\u0627\u0632 \u0627\u0644\u0646\u0645\u0648\u0630\u062c (GPU \u0623\u0648 CPU)\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "inputs.pop(\"token_type_ids\", None)\n",
        "\n",
        "# \u062a\u0648\u0644\u064a\u062f \u0627\u0644\u0646\u0635 (\u0627\u0644\u0648\u0635\u0641)\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=51)\n",
        "\n",
        "output = processor.decode(\n",
        "    generated_ids[0][ inputs[\"input_ids\"].shape[1]: ],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "Kkl7fd4FhXUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/zai-org/GLM-4.6V-Flash/discussions/15"
      ],
      "metadata": {
        "id": "XPVOj1fXhiSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "/content/Grayscale_8bits_palette_sample_image.png"
      ],
      "metadata": {
        "id": "61EIPmHZhjKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "918a97c8",
        "outputId": "219ab2f5-aa41-443a-ff9c-d44b021d2dcb"
      },
      "source": [
        "from IPython.display import Image as IPImage\n",
        "\n",
        "# \u062a\u0623\u0643\u062f \u0623\u0646 \u0645\u0633\u0627\u0631 \u0627\u0644\u0635\u0648\u0631\u0629 \u0635\u062d\u064a\u062d\n",
        "image_path = \"/content/Grayscale_8bits_palette_sample_image.png\"\n",
        "\n",
        "# \u0639\u0631\u0636 \u0627\u0644\u0635\u0648\u0631\u0629\n",
        "IPImage(filename=image_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}